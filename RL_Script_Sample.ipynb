{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL for LDI Sample Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kailan Shang\n",
    "\n",
    "Date: Dec. 29, 2020\n",
    "\n",
    "This script is made available for educational purpose, as part of a research project sponsored by the Society of Actuaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages. You will need to install them before you can run the sript\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "#Import data inputs. Data files are avialable in the Github repository. Once downloaded, the directories listed below may be\n",
    "#changed to your own directories\n",
    "MacroFactor = ['gdpgr','pconsump','cpi','Unemploy','m3tb','tb10y','aa10y','gpdinv']\n",
    "VARModel = 'C:/dsge/py/input/var.csv'\n",
    "Mapping = 'C:/dsge/py/input/mapping.csv'\n",
    "Mortality = 'C:/dsge/py/input/mortality.csv'\n",
    "Census = 'C:/dsge/py/input/census.csv'\n",
    "RecFun = [77.96,66.31,0.34,-1.23,-25.34,-51.33,-3.4,-9.86,-8.45,-32.19,4.26,0.12,-17.02]\n",
    "histMF = 'C:/dsge/py/input/histMF.csv' \n",
    "histAR = 'C:/dsge/py/input/histAR.csv'\n",
    "cholMF = 'C:/dsge/py/input/var1chol.csv'\n",
    "cholNormal = 'C:/dsge/py/input/normalcholf.csv'\n",
    "cholRecession = 'C:/dsge/py/input/recessioncholf.csv'\n",
    "termmix = 'C:/dsge/py/input/termmix.csv'\n",
    "migration = 'C:/dsge/py/input/migration.csv'\n",
    "\n",
    "#Set the seed of random nunber generation\n",
    "random.seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu will be used\n"
     ]
    }
   ],
   "source": [
    "#Check if GPU is available. This script can be run on CPUs but for training process, GPUs are a better choice.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu will be used\")\n",
    "else:\n",
    "    print(\"cpu will be used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESG based on LDI Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ESG following the rules specified in the LDI Benchmark Model paper: https://www.soa.org/resources/research-reports/2019/liability-driven-investment/\n",
    "\n",
    "The generation of bond fund returns based on credit rating and rebalancing strategies is time consuming.\n",
    "\n",
    "Pregenerated scenarios may be used to avoid long run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the recession function used in ESG\n",
    "def recession(fun,vals):\n",
    "    vals.insert(0,1)\n",
    "    prob = 1/(1+math.exp(-sum([x*y for x,y in zip(fun, vals)])))\n",
    "    if prob > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#y = [6.358,0.617,0.921,0.454,6.357,0.680,0.931,0.463,6.349,0.732,0.940,0.471]\n",
    "#recession(RecFun,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kshang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:112: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\kshang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:122: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.92409196, 0.88333742, 0.77436223],\n",
       "       [0.92409196, 1.        , 0.88729608, 0.81387481],\n",
       "       [0.88333742, 0.88729608, 1.        , 0.97511871],\n",
       "       [0.77436223, 0.81387481, 0.97511871, 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fully stochastic scenario generation\n",
    "scale = 1.0 #Scaling of volatilty. If set to 1.0, historical calibration is used.\n",
    "def sampleMF(var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,dyn,n,stochastic=True):\n",
    "\tvar = np.array(var)\n",
    "\tfundmap = np.array(fundmap)\n",
    "\thistMF = np.array(histMF)\n",
    "\thistAR = np.array(histAR)\n",
    "\tcholMF = np.array(cholMF)\n",
    "\tcholNormal = np.array(cholNormal)\n",
    "\tcholRecession = np.array(cholRecession)\n",
    "\tif stochastic==True and dyn>=n:\n",
    "\t\tsd = var[:,[8]]\n",
    "\t\tvar = var[:,[range(0,9)]]\n",
    "\t\thmf = histMF\n",
    "\t\thmf3 = np.insert(hmf,0,hmf[hmf.shape[0]-2,:],0)\n",
    "\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\trece = recession(RecFun,recessionVal)\n",
    "\t\thmf = hmf[hmf.shape[0]-1,:]\n",
    "\t\tthmf = np.append(hmf,rece)\n",
    "\t\tsdtnormal = np.sqrt(fundmap[:,[27]])/scale\n",
    "\t\tsdtrecession = np.sqrt(fundmap[:,[28]])/scale\n",
    "\t\tsdinormal = np.sqrt(fundmap[:,[29]])/scale\n",
    "\t\tsdirecession = fundmap[:,[30]]/scale\n",
    "\t\tcorrnormal = fundmap[:,[31]]\n",
    "\t\tcorrrecession = fundmap[:,[32]]\n",
    "\t\tfundmap = fundmap[:,[range(0,27)]]\n",
    "\t\thar = histAR\n",
    "\t\thar3 = np.insert(har,0,har[har.shape[0]-2,:],0)\n",
    "\t\thar = har[har.shape[0]-1,:]\n",
    "\t\tthmf = np.append(thmf,har)\n",
    "\t\thmf=np.append(hmf,1)\n",
    "\t\tfor i in range(0,n):\n",
    "\t\t\thmf = var.dot(hmf.T).T\n",
    "\t\t\thmf = hmf + np.multiply(sd.T,np.dot(cholMF,np.array(np.random.normal(0,1,8)).T))\n",
    "\t\t\thmf3[0] = hmf3[1]\n",
    "\t\t\thmf3[1] = hmf3[2]\n",
    "\t\t\thmf3[2] = hmf\n",
    "\t\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\t\trece = recession(RecFun,recessionVal)\n",
    "\t\t\tfor j in range(0,har.shape[0]):\n",
    "\t\t\t\thartmp = hmf3.flatten('F')\n",
    "\t\t\t\thartmp = np.insert(hartmp,0,[1,har3[1,j],har3[2,j]])\n",
    "\t\t\t\thar[j] = fundmap[j].dot(hartmp.T).T\n",
    "\t\t\tif rece==0:\n",
    "\t\t\t\trnds = np.multiply(sdinormal.T, np.dot(cholNormal,np.array(np.random.normal(0,1,33)).T))\n",
    "\t\t\t\trnds = np.multiply((np.multiply(corrnormal.T,har) + np.multiply(np.sqrt(1-np.multiply(corrnormal.T,corrnormal.T)),rnds)),sdinormal.T)\n",
    "\t\t\t\trnds = np.divide(rnds,np.sqrt(np.multiply(np.multiply(corrnormal.T,corrnormal.T),np.multiply(sdtnormal.T,sdtnormal.T))+np.multiply((1-np.multiply(corrnormal.T,corrnormal.T)),np.multiply(sdinormal.T,sdinormal.T))))\n",
    "\t\t\t\trnds[0,5]=0 #set random numbers to be zero for those already generated in economic factors.\n",
    "\t\t\t\trnds[0,8]=0\n",
    "\t\t\t\trnds[0,10]=0\n",
    "\t\t\t\trnds[0,30]=0\n",
    "\t\t\t\trnds[0,31]=0\n",
    "\t\t\t\thar = har + rnds.flatten('F')\n",
    "\t\t\telse:\n",
    "\t\t\t\trnds = np.multiply(sdirecession.T, np.dot(cholRecession,np.array(np.random.normal(0,1,33)).T))\n",
    "\t\t\t\trnds = np.multiply((np.multiply(corrrecession.T,har) + np.multiply(np.sqrt(1-np.multiply(corrrecession.T,corrrecession.T)),rnds)),sdirecession.T)\n",
    "\t\t\t\trnds = np.divide(rnds,np.sqrt(np.multiply(np.multiply(corrrecession.T,corrrecession.T),np.multiply(sdtrecession.T,sdtrecession.T))+np.multiply((1-np.multiply(corrrecession.T,corrrecession.T)),np.multiply(sdirecession.T,sdirecession.T))))\n",
    "\t\t\t\trnds[0,5]=0\n",
    "\t\t\t\trnds[0,8]=0\n",
    "\t\t\t\trnds[0,10]=0\n",
    "\t\t\t\trnds[0,30]=0\n",
    "\t\t\t\trnds[0,31]=0\n",
    "\t\t\t\thar = har + rnds.flatten('F')\n",
    "\t\t\tfor ix in range(0,8):\n",
    "\t\t\t\thar[ix]=max(0.1,har[ix])\n",
    "\t\t\tfor ix in [10,12,14,16]:\n",
    "\t\t\t\thar[ix]=max(0,har[ix])\n",
    "\t\t\tfor ix in range(0,har.shape[0]):\n",
    "\t\t\t\thar[ix]=max(-99,har[ix])\n",
    "\t\t\thar3[0] = har3[1]\n",
    "\t\t\thar3[1] = har3[2]\n",
    "\t\t\thar3[2] = har\n",
    "\t\t\tthmf = np.vstack([thmf, np.append(np.append(hmf,rece),har.flatten())])\n",
    "\t\t\thmf=np.append(hmf,1)\n",
    "\t\treturn thmf\n",
    "\telif stochastic==True and dyn>0 and dyn<n:\n",
    "\t\tsd = var[:,[8]]\n",
    "\t\tvar = var[:,[range(0,9)]]\n",
    "\t\thmf = histMF\n",
    "\t\thmf3 = np.insert(hmf,0,hmf[hmf.shape[0]-2,:],0)\n",
    "\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\trece = recession(RecFun,recessionVal)\n",
    "\t\thmf = hmf[hmf.shape[0]-1,:]\n",
    "\t\tthmf = np.append(hmf,rece)\n",
    "\t\tsdtnormal = fundmap[:,[27]]/scale\n",
    "\t\tsdtrecession = fundmap[:,[28]]/scale\n",
    "\t\tsdinormal = fundmap[:,[29]]/scale\n",
    "\t\tsdirecession = fundmap[:,[30]]/scale\n",
    "\t\tcorrnormal = fundmap[:,[31]]\n",
    "\t\tcorrrecession = fundmap[:,[32]]\n",
    "\t\tfundmap = fundmap[:,[range(0,27)]]\n",
    "\t\thar = histAR\n",
    "\t\thar3 = np.insert(har,0,har[har.shape[0]-2,:],0)\n",
    "\t\thar = har[har.shape[0]-1,:]\n",
    "\t\tthmf = np.append(thmf,har)\n",
    "\t\thmf=np.append(hmf,1)\n",
    "\t\tfor i in range(0,dyn):\n",
    "\t\t\thmf = var.dot(hmf.T).T\n",
    "\t\t\thmf = hmf + np.multiply(sd.T,np.dot(cholMF,np.array(np.random.normal(0,1,8)).T))\n",
    "\t\t\thmf3[0] = hmf3[1]\n",
    "\t\t\thmf3[1] = hmf3[2]\n",
    "\t\t\thmf3[2] = hmf\n",
    "\t\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\t\trece = recession(RecFun,recessionVal)\n",
    "\t\t\tfor j in range(0,har.shape[0]):\n",
    "\t\t\t\thartmp = hmf3.flatten('F')\n",
    "\t\t\t\thartmp = np.insert(hartmp,0,[1,har3[1,j],har3[2,j]])\n",
    "\t\t\t\thar[j] = fundmap[j].dot(hartmp.T).T\n",
    "\t\t\tif rece==0:\n",
    "\t\t\t\trnds = np.multiply(sdinormal.T, np.dot(cholNormal,np.array(np.random.normal(0,1,33)).T))\n",
    "\t\t\t\trnds = np.multiply((np.multiply(corrnormal.T,har) + np.multiply(np.sqrt(1-np.multiply(corrnormal.T,corrnormal.T)),rnds)),sdinormal.T)\n",
    "\t\t\t\trnds = np.divide(rnds,np.sqrt(np.multiply(np.multiply(corrnormal.T,corrnormal.T),np.multiply(sdtnormal.T,sdtnormal.T))+np.multiply((1-np.multiply(corrnormal.T,corrnormal.T)),np.multiply(sdinormal.T,sdinormal.T))))\n",
    "\t\t\t\trnds[0,5]=0\n",
    "\t\t\t\trnds[0,8]=0\n",
    "\t\t\t\trnds[0,10]=0\n",
    "\t\t\t\trnds[0,30]=0\n",
    "\t\t\t\trnds[0,31]=0\n",
    "\t\t\t\thar = har + rnds.flatten('F')\n",
    "\t\t\telse:\n",
    "\t\t\t\trnds = np.multiply(sdirecession.T, np.dot(cholRecession,np.array(np.random.normal(0,1,33)).T))\n",
    "\t\t\t\trnds = np.multiply((np.multiply(corrrecession.T,har) + np.multiply(np.sqrt(1-np.multiply(corrrecession.T,corrrecession.T)),rnds)),sdirecession.T)\n",
    "\t\t\t\trnds = np.divide(rnds,np.sqrt(np.multiply(np.multiply(corrrecession.T,corrrecession.T),np.multiply(sdtrecession.T,sdtrecession.T))+np.multiply((1-np.multiply(corrrecession.T,corrrecession.T)),np.multiply(sdirecession.T,sdirecession.T))))\n",
    "\t\t\t\trnds[0,5]=0\n",
    "\t\t\t\trnds[0,8]=0\n",
    "\t\t\t\trnds[0,10]=0\n",
    "\t\t\t\trnds[0,30]=0\n",
    "\t\t\t\trnds[0,31]=0\n",
    "\t\t\t\thar = har + rnds.flatten('F')\n",
    "\t\t\tfor ix in range(0,8):\n",
    "\t\t\t\thar[ix]=max(0.1,har[ix])\n",
    "\t\t\tfor ix in [10,12,14,16]:\n",
    "\t\t\t\thar[ix]=max(0,har[ix])\n",
    "\t\t\tfor ix in range(0,har.shape[0]):\n",
    "\t\t\t\thar[ix]=max(-99,har[ix])\n",
    "\t\t\thar3[0] = har3[1]\n",
    "\t\t\thar3[1] = har3[2]\n",
    "\t\t\thar3[2] = har\n",
    "\t\t\tthmf = np.vstack([thmf, np.append(np.append(hmf,rece),har.flatten())])\n",
    "\t\t\thmf=np.append(hmf,1)\n",
    "\t\tfor i in range(dyn,n):\n",
    "\t\t\thmf = var.dot(hmf.T).T\n",
    "\t\t\thmf3[0] = hmf3[1]\n",
    "\t\t\thmf3[1] = hmf3[2]\n",
    "\t\t\thmf3[2] = hmf\n",
    "\t\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\t\trece = recession(RecFun,recessionVal)\n",
    "\t\t\tfor j in range(0,har.shape[0]):\n",
    "\t\t\t\thartmp = hmf3.flatten('F')\n",
    "\t\t\t\thartmp = np.insert(hartmp,0,[1,har3[1,j],har3[2,j]])\n",
    "\t\t\t\thar[j] = fundmap[j].dot(hartmp.T).T\n",
    "\t\t\tfor ix in range(0,8):\n",
    "\t\t\t\thar[ix]=max(0.1,har[ix])\n",
    "\t\t\tfor ix in [10,12,14,16]:\n",
    "\t\t\t\thar[ix]=max(0,har[ix])\n",
    "\t\t\tfor ix in range(0,har.shape[0]):\n",
    "\t\t\t\thar[ix]=max(-99,har[ix])\n",
    "\t\t\thar3[0] = har3[1]\n",
    "\t\t\thar3[1] = har3[2]\n",
    "\t\t\thar3[2] = har\n",
    "\t\t\tthmf = np.vstack([thmf, np.append(np.append(hmf,rece),har.flatten())])\n",
    "\t\t\thmf=np.append(hmf,1)\n",
    "\t\treturn thmf\n",
    "\telse:\n",
    "\t\tvar = var[:,[range(0,9)]]\n",
    "\t\thmf = histMF\n",
    "\t\thmf3 = np.insert(hmf,0,hmf[hmf.shape[0]-2,:],0)\n",
    "\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\trece = recession(RecFun,recessionVal)\n",
    "\t\thmf = hmf[hmf.shape[0]-1,:]\n",
    "\t\tthmf = np.append(hmf,rece)\n",
    "\t\tsdtnormal = fundmap[:,[27]]/scale\n",
    "\t\tsdtrecession = fundmap[:,[28]]/scale\n",
    "\t\tsdinormal = fundmap[:,[29]]/scale\n",
    "\t\tsdirecession = fundmap[:,[30]]/scale\n",
    "\t\tcorrnormal = fundmap[:,[31]]\n",
    "\t\tcorrrecession = fundmap[:,[32]]\n",
    "\t\tfundmap = fundmap[:,[range(0,27)]]\n",
    "\t\thar = histAR\n",
    "\t\thar3 = np.insert(har,0,har[har.shape[0]-2,:],0)\n",
    "\t\thar = har[har.shape[0]-1,:]\n",
    "\t\tthmf = np.append(thmf,har)\n",
    "\t\thmf=np.append(hmf,1)\n",
    "\t\tfor i in range(0,n):\n",
    "\t\t\thmf = var.dot(hmf.T).T\n",
    "\t\t\thmf3[0] = hmf3[1]\n",
    "\t\t\thmf3[1] = hmf3[2]\n",
    "\t\t\thmf3[2] = hmf\n",
    "\t\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\t\trece = recession(RecFun,recessionVal)\n",
    "\t\t\tfor j in range(0,har.shape[0]):\n",
    "\t\t\t\thartmp = hmf3.flatten('F')\n",
    "\t\t\t\thartmp = np.insert(hartmp,0,[1,har3[1,j],har3[2,j]])\n",
    "\t\t\t\thar[j] = fundmap[j].dot(hartmp.T).T\n",
    "\t\t\tfor ix in range(0,8):\n",
    "\t\t\t\thar[ix]=max(0.1,har[ix])\n",
    "\t\t\tfor ix in [10,12,14,16]:\n",
    "\t\t\t\thar[ix]=max(0,har[ix])\n",
    "\t\t\tfor ix in range(0,har.shape[0]):\n",
    "\t\t\t\thar[ix]=max(-99,har[ix])\n",
    "\t\t\thar3[0] = har3[1]\n",
    "\t\t\thar3[1] = har3[2]\n",
    "\t\t\thar3[2] = har\n",
    "\t\t\tthmf = np.vstack([thmf, np.append(np.append(hmf,rece),har.flatten())])\n",
    "\t\t\thmf=np.append(hmf,1)\n",
    "\t\treturn thmf\n",
    "\n",
    "var = pd.read_csv(VARModel)\n",
    "hmf = pd.read_csv(histMF)\n",
    "var1chol = pd.read_csv(cholMF)\n",
    "fundmap = pd.read_csv(Mapping)\n",
    "har = pd.read_csv(histAR)\n",
    "normalChol = pd.read_csv(cholNormal)\n",
    "recessionChol = pd.read_csv(cholRecession)\n",
    "thmf=sampleMF(var,fundmap,hmf,har,var1chol,normalChol,recessionChol,5,30,stochastic=True)\n",
    "np.corrcoef(thmf[:,[18,20,22,24]],rowvar=False)\n",
    "\n",
    "# check = sampleMF(var,fundmap,hmf,har,var1chol,normalChol,recessionChol,60,60,stochastic=False)\n",
    "# check[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for period after n, genearte expected scenarios instead of stochastic scenarios\n",
    "def sampleMF2(thmf,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,dyn,n):\n",
    "\tvar = np.array(var)\n",
    "\tfundmap = np.array(fundmap)\n",
    "\thistMF = np.array(histMF)\n",
    "\thistAR = np.array(histAR)\n",
    "\tcholMF = np.array(cholMF)\n",
    "\tcholNormal = np.array(cholNormal)\n",
    "\tcholRecession = np.array(cholRecession)\n",
    "\n",
    "\tsd = var[:,[8]]\n",
    "\tvar = var[:,[range(0,9)]]\n",
    "\thmf = histMF\n",
    "\thmf3 = np.insert(hmf,0,hmf[hmf.shape[0]-2,:],0)\n",
    "\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\trece = recession(RecFun,recessionVal)\n",
    "\thmf = hmf[hmf.shape[0]-1,:]\n",
    "\tsdtnormal = fundmap[:,[27]]/scale\n",
    "\tsdtrecession = fundmap[:,[28]]/scale\n",
    "\tsdinormal = fundmap[:,[29]]/scale\n",
    "\tsdirecession = fundmap[:,[30]]/scale\n",
    "\tcorrnormal = fundmap[:,[31]]\n",
    "\tcorrrecession = fundmap[:,[32]]\n",
    "\tfundmap = fundmap[:,[range(0,27)]]\n",
    "\thar = histAR\n",
    "\thar3 = np.insert(har,0,har[har.shape[0]-2,:],0)\n",
    "\thar = har[har.shape[0]-1,:]\n",
    "\thmf=np.append(hmf,1)\n",
    "\n",
    "\tthmf = thmf[range(0,dyn+1),:]\n",
    "\thar = thmf[dyn,range(9,42)]\n",
    "\thmf = thmf[dyn,range(0,8)]\n",
    "\n",
    "\tif dyn==1:\n",
    "\t\thar3[0]=har3[1]\n",
    "\t\thar3[1]=har3[2]\n",
    "\t\thar3[2]=har\n",
    "\t\thmf3[0] = hmf3[1]\n",
    "\t\thmf3[1] = hmf3[2]\n",
    "\t\thmf3[2] = hmf\n",
    "\telif dyn==2:\n",
    "\t\thar3[0]=har3[2]\n",
    "\t\thar3[1]=thmf[dyn-1,range(9,42)]\n",
    "\t\thar3[2]=har\n",
    "\t\thmf3[0] = hmf3[2]\n",
    "\t\thmf3[1] = thmf[dyn-1,range(0,8)]\n",
    "\t\thmf3[2] = hmf\n",
    "\telif dyn>2:\n",
    "\t\thar3[0]=thmf[dyn-2,range(9,42)]\n",
    "\t\thar3[1]=thmf[dyn-1,range(9,42)]\n",
    "\t\thar3[2]=har\n",
    "\t\thmf3[0] = thmf[dyn-2,range(0,8)]\n",
    "\t\thmf3[1] = thmf[dyn-1,range(0,8)]\n",
    "\t\thmf3[2] = hmf\n",
    "\t\t\n",
    "\thmf=np.append(hmf,1)\n",
    "\t\n",
    "\tfor i in range(dyn,n):\n",
    "\t\thmf = var.dot(hmf.T).T\n",
    "\t\thmf3[0] = hmf3[1]\n",
    "\t\thmf3[1] = hmf3[2]\n",
    "\t\thmf3[2] = hmf\n",
    "\t\trecessionVal = [hmf3[2,3],hmf3[2,7],hmf3[2,1],hmf3[2,0],hmf3[1,3],hmf3[1,7],hmf3[1,1],hmf3[1,0],hmf3[0,3],hmf3[0,7],hmf3[0,1],hmf3[0,0]]\n",
    "\t\trece = recession(RecFun,recessionVal)\n",
    "\t\tfor j in range(0,har.shape[0]):\n",
    "\t\t\thartmp = hmf3.flatten('F')\n",
    "\t\t\thartmp = np.insert(hartmp,0,[1,har3[1,j],har3[2,j]])\n",
    "\t\t\thar[j] = fundmap[j].dot(hartmp.T).T\n",
    "\t\tfor ix in range(0,8):\n",
    "\t\t\thar[ix]=max(0.1,har[ix])\n",
    "\t\tfor ix in [10,12,14,16]:\n",
    "\t\t\thar[ix]=max(0,har[ix])\n",
    "\t\tfor ix in range(0,har.shape[0]):\n",
    "\t\t\thar[ix]=max(-99,har[ix])\n",
    "\t\thar3[0] = har3[1]\n",
    "\t\thar3[1] = har3[2]\n",
    "\t\thar3[2] = har\n",
    "\t\tthmf = np.vstack([thmf, np.append(np.append(hmf,rece),har.flatten())])\n",
    "\t\thmf=np.append(hmf,1)\n",
    "\treturn thmf\n",
    "\n",
    "# sampleMF2(thmf, var,fundmap,hmf,har,var1chol,normalChol,recessionChol,5,30)[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "x = np.array([1,2,3,5,7,10,20])\n",
    "y = np.array([0.5,1.1,1.2,1.9,2.15,2.5,3])\n",
    "f = interp1d(x, y)\n",
    "f2 = interp1d(x, y, kind='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xnew = np.linspace(1, 20, num=41, endpoint=True)\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(x, y, 'o', xnew, f(xnew), '-', xnew, f2(xnew), '--')\n",
    "#plt.legend(['data', 'linear', 'cubic'], loc='best')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curvefitting(value,term=np.array([0.25,1,2,3,5,7,10,20,30]),inter=\"linear\",extro=\"cfr\",target=0.04):\n",
    "\tif value.shape[0] != term.shape[0]:\n",
    "\t\treturn -1\n",
    "\telse:\n",
    "\t\tstartT = term[0]\n",
    "\t\tendT = term[term.shape[0]-1]\n",
    "\t\tsecondEndT = term[term.shape[0]-2]\n",
    "\t\txnew = np.linspace(startT,endT,num=int(round((endT-startT)*4+1)),endpoint=True)\n",
    "\t\tif inter==\"linear\":\n",
    "\t\t\tf = interp1d(term, value)\n",
    "\t\telse:\n",
    "\t\t\tf = interp1d(term, value, kind='cubic')\n",
    "\t\tynew = f(xnew)\n",
    "\t\tif endT < 100:\n",
    "\t\t\txnew2 = np.linspace(endT+0.25,100,num=int(round((100-endT)*4)),endpoint=True)\n",
    "\t\t\tynew2=[]\n",
    "\t\t\tif extro==\"cfr\":\n",
    "\t\t\t\tcfr = (((1+value[value.shape[0]-1]) ** endT)/((1+value[value.shape[0]-2]) ** secondEndT)) ** (1/(endT-secondEndT))-1\n",
    "\t\t\t\tcumfac = (1+value[value.shape[0]-1]) ** endT\n",
    "\t\t\t\tfor ix in xnew2:\n",
    "\t\t\t\t\tcumfac = cumfac*(1+cfr)**(1/4)\n",
    "\t\t\t\t\tynew2.append(cumfac**(1/ix)-1)\n",
    "\t\t\telse:\n",
    "\t\t\t\tp = np.poly1d(np.polyfit(np.array([secondEndT,endT,100]),np.array([value[value.shape[0]-2],value[value.shape[0]-1],target]),deg=2))\n",
    "\t\t\t\tynew2 = p(xnew2)\n",
    "\t\tx = np.append(xnew,xnew2)\n",
    "\t\ty = np.append(ynew,ynew2)\n",
    "\t\treturn x,y\n",
    "\n",
    "# xi,yi = curvefitting(np.array([0.25,0.3,0.5,1.1,1.2,1.9,2.15,2.5,3])/100,inter=\"linear\",extro=\"tar\")\n",
    "# term = np.array([0.25,1,2,3,5,7,10,20,30])\n",
    "# value = np.array([0.25,0.3,0.5,1.1,1.2,1.9,2.15,2.5,3])/100\n",
    "# plt.plot(term, value, 'o', xi, yi, '-')\n",
    "# plt.legend(['data', 'linear'], loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21755.153866790886"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bond pricer\n",
    "def bondPrice(terms,rates,term,freq,coupon,redemption,inter=\"linear\",extro=\"tar\",expectedRate=0.04):\n",
    "\txi,yi = curvefitting(rates,terms,inter=inter,extro=extro,target=expectedRate)\n",
    "\tf = interp1d(xi,yi)\n",
    "\tif term > 0.25:\n",
    "\t\tbondvalue = redemption*(1+coupon*freq)/(1+f(term))**term\n",
    "\telse:\n",
    "\t\tbondvalue = redemption\n",
    "\tfor i in np.arange(term-freq,0.01,-freq):\n",
    "\t\tbondvalue = bondvalue + redemption*coupon*freq/(1+f(i))**(i)\n",
    "\treturn bondvalue\n",
    "term = np.array([0.25,1,2,3,5,7,10,20,30])\n",
    "value = np.array([0.575593169+0.457631,0.842160583+0.457631,1.20,1.47,1.93,2.25,2.45,2.79,3.06])/100\n",
    "bondPrice(term,value,0.75,1,1.14/100,21705)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bond fund return calculator for each credit rating with a target duration and rebalancing strategy\n",
    "def bondReturn(thmf,mix,migrationM,dyn=10,n=10,rating=2,rebalance=0.5,bondfreq=0.25,inter=\"linear\",extro=\"tar\",expectedRate=0.04):\n",
    "#rating: 0-Govt Bond; 1-AAA; 2-AA; 3-A; 4-BBB\n",
    "\tterm = np.array([0.25,1,2,3,5,7,10,20,30])\n",
    "\tinitialVal = 1000000\n",
    "\tmigrationM = np.array(migrationM)/100\n",
    "\trecoveryM = migrationM[:,6]*100\n",
    "\tmix = np.array(mix)\n",
    "\t#rating=2\n",
    "\t#bondfreq=0.25\n",
    "\tMVM = mix[rating] * initialVal\n",
    "\tvalue = thmf[0,[4,9,10,11,12,13,14,15,16]]\n",
    "\tif rating>0:\n",
    "\t\tvalue = value + thmf[0,16+rating*2]\n",
    "\tdefault= np.append(0,thmf[0,[19,21,23,25]])/100\n",
    "\txnew = np.linspace(0.25,30,num=120,endpoint=True)\n",
    "\tinter=\"linear\"\n",
    "\tif inter==\"linear\":\n",
    "\t\tf = interp1d(term,value)\n",
    "\telse:\n",
    "\t\tf = interp1d(term,value,kind='cubic')\n",
    "\tCouponM = np.array(f(xnew))\n",
    "\tFVM = np.copy(MVM)\n",
    "\tfor i in range(0,120):\n",
    "\t\tFVM[i] = FVM[i]/bondPrice(term,value/100,(i+1)*0.25,bondfreq,CouponM[i]/100,1,inter=inter,extro=extro,expectedRate=expectedRate)\n",
    "\tnBSM = np.repeat(0.0,120)\n",
    "\tRedemptionM = np.repeat(0.0,120)\n",
    "\ttMVM = np.copy(MVM)\n",
    "\ttFVM = np.copy(FVM)\n",
    "\ttBSM = np.copy(nBSM)\n",
    "\ttRDM = np.copy(RedemptionM)\n",
    "\ttCRM = np.copy(CouponM)\n",
    "\tcashRtn = []\n",
    "\tpriceRtn = []\n",
    "\n",
    "\tfor i in range(1,thmf.shape[0]):\n",
    "\t\tbcurve = thmf[i,[4,9,10,11,12,13,14,15,16]]\n",
    "\t\tbcurve = np.vstack([bcurve,bcurve + thmf[i,18]])\n",
    "\t\tbcurve = np.vstack([bcurve,bcurve[0] + thmf[i,20]])\n",
    "\t\tbcurve = np.vstack([bcurve,bcurve[0] + thmf[i,22]])\n",
    "\t\tbcurve = np.vstack([bcurve,bcurve[0] + thmf[i,24]])\n",
    "\t\tbcurve = np.vstack([bcurve,bcurve[4] + 2.499197])\n",
    "\t\t#if i==1:\n",
    "\t\t\t#print bcurve\n",
    "\t\tnMVM = np.repeat(0.0,120)\n",
    "\t\tnFVM = np.repeat(0.0,120)\n",
    "\t\tnBSM = np.repeat(0.0,120)\n",
    "\t\tRedemptionM = np.repeat(0.0,120)\n",
    "\n",
    "\t\ttotalBS = 0.0\n",
    "\t\txnew = np.linspace(0.25,30,num=120,endpoint=True)\n",
    "\t\tinter=\"linear\"\n",
    "\t\tif inter==\"linear\":\n",
    "\t\t\tf = interp1d(term,bcurve[rating])\n",
    "\t\telse:\n",
    "\t\t\tf = interp1d(term,bcurve[rating],kind='cubic')\n",
    "\t\tnCouponM = np.array(f(xnew))\n",
    "\t\tfor j in range(0,120):\n",
    "\t\t\tfor k in range(0,6):\n",
    "\t\t\t\tif k==rating:\n",
    "\t\t\t\t\tnMVM[j] = bondPrice(term,bcurve[rating]/100,(j+1)/4.0-0.25,bondfreq,CouponM[j]/100,FVM[j],inter=inter,extro=extro,expectedRate=expectedRate)*migrationM[rating,rating]*(1-default[rating]*(1-recoveryM[rating]))\n",
    "\t\t\t\t\tnFVM[j] = FVM[j]*migrationM[rating,rating]*(1-default[rating]*(1-recoveryM[rating]))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttotalBS = totalBS + bondPrice(term,bcurve[k]/100,(j+1)/4.0-0.25,bondfreq,CouponM[j]/100,FVM[j],inter=inter,extro=extro,expectedRate=expectedRate)*migrationM[rating,k]*(1-default[rating]*(1-recoveryM[rating]))\n",
    "\t\t\tif j==0:\n",
    "\t\t\t\tRedemptionM[j] = nMVM[j]*(1-default[rating]*(1-recoveryM[rating]))\n",
    "\t\t\tif ((j+1)%int(bondfreq*4)==1 and bondfreq>0.25) or bondfreq==0.25:\n",
    "\t\t\t\tRedemptionM[j] = RedemptionM[j] + FVM[j]*CouponM[j]/100*bondfreq*(1-default[rating]*(1-recoveryM[rating]))\n",
    "\t\n",
    "\t\ttotalBS = totalBS + np.sum(RedemptionM)\n",
    "\t\tif rebalance==0:\n",
    "\t\t\tnBSM=totalBS*mix[rating]\n",
    "\t\t\tnBSFM = np.repeat(0.0,120)\n",
    "\t\t\tfor j in range(0,120):\n",
    "\t\t\t\tnBSFM[j] = nBSM[j]/bondPrice(term,bcurve[rating]/100,(j+1)/4.0,bondfreq,nCouponM[j]/100,1)\n",
    "\t\t\tfor j in range(1,120):\n",
    "\t\t\t\tMVM[j-1]=nMVM[j]\n",
    "\t\t\t\tFVM[j-1]=nFVM[j]\n",
    "\t\t\tMVM[119]=0\n",
    "\t\t\tFVM[119]=0\n",
    "\t\t\tfor j in range(1,120):\n",
    "\t\t\t\tif (FVM[j-1]+nBSFM[j-1]) != 0:\n",
    "\t\t\t\t\tCouponM[j-1]=(FVM[j-1]*CouponM[j]+nBSFM[j-1]*nCouponM[j-1])/(FVM[j-1]+nBSFM[j-1])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tCouponM[j-1]=CouponM[j]\n",
    "\t\t\tCouponM[119]=nCouponM[119]\n",
    "\t\t\tMVM = MVM + nBSM\n",
    "\t\t\tFVM = FVM + nBSFM\n",
    "\t\telif i%int(rebalance*4)==0:\n",
    "\t\t\ttotalBS = totalBS + np.sum(nMVM)\n",
    "\t\t\tnBSM=totalBS*mix[rating]\n",
    "\t\t\tfor j in range(0,119):\n",
    "\t\t\t\tnBSM[j] = nBSM[j]-nMVM[j+1]\n",
    "\t\t\tnBSFM = np.repeat(0.0,120)\n",
    "\t\t\tfor j in range(0,120):\n",
    "\t\t\t\tif nBSM[j]<0:\n",
    "\t\t\t\t\tnBSFM[j] = nBSM[j]/bondPrice(term,bcurve[rating]/100,(j+1)/4.0,bondfreq,CouponM[j+1]/100,1,inter=inter,extro=extro,expectedRate=expectedRate)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnBSFM[j] = nBSM[j]/bondPrice(term,bcurve[rating]/100,(j+1)/4.0,bondfreq,nCouponM[j]/100,1,inter=inter,extro=extro,expectedRate=expectedRate)\t\t\t\t\n",
    "\t\t\tfor j in range(1,120):\n",
    "\t\t\t\tMVM[j-1]=nMVM[j]\n",
    "\t\t\t\tFVM[j-1]=nFVM[j]\n",
    "\t\t\tMVM[119]=0\n",
    "\t\t\tFVM[119]=0\n",
    "\t\t\tfor j in range(1,120):\n",
    "\t\t\t\tif nBSM[j-1]>0 and (FVM[j-1]+nBSFM[j-1])!=0:\n",
    "\t\t\t\t\tCouponM[j-1]=(FVM[j-1]*CouponM[j]+nBSFM[j-1]*nCouponM[j-1])/(FVM[j-1]+nBSFM[j-1])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tCouponM[j-1]=CouponM[j]\n",
    "\t\t\tCouponM[119]=nCouponM[119]\n",
    "\t\t\tMVM = MVM + nBSM\n",
    "\t\t\tFVM = FVM + nBSFM\n",
    "\t\telse:\n",
    "\t\t\tnBSM=totalBS*mix[rating]\n",
    "\t\t\tnBSFM = np.repeat(0.0,120)\n",
    "\t\t\tfor j in range(0,120):\n",
    "\t\t\t\tnBSFM[j] = nBSM[j]/bondPrice(term,value/100,(j+1)/4,bondfreq,nCouponM[j]/100,1,inter=inter,extro=extro,expectedRate=expectedRate)\n",
    "\t\t\tfor j in range(1,120):\n",
    "\t\t\t\tMVM[j-1]=nMVM[j]\n",
    "\t\t\t\tFVM[j-1]=nFVM[j]\n",
    "\t\t\tMVM[119]=0\n",
    "\t\t\tFVM[119]=0\n",
    "\t\t\tfor j in range(1,120):\n",
    "\t\t\t\tif (FVM[j-1]+nBSFM[j-1]) != 0:\n",
    "\t\t\t\t\tCouponM[j-1]=(FVM[j-1]*CouponM[j]+nBSFM[j-1]*nCouponM[j-1])/(FVM[j-1]+nBSFM[j-1])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tCouponM[j-1]=CouponM[j]\n",
    "\t\t\tCouponM[119]=nCouponM[119]\n",
    "\t\t\tMVM = MVM + nBSM\n",
    "\t\t\tFVM = FVM + nBSFM\n",
    "\t\ttMVM = np.vstack([tMVM,MVM])\n",
    "\t\ttFVM = np.vstack([tFVM,FVM])\n",
    "\t\ttBSM = np.vstack([tBSM,nBSM])\n",
    "\t\ttRDM = np.vstack([tRDM,RedemptionM])\n",
    "\t\ttCRM = np.vstack([tCRM,CouponM])\n",
    "\t\tcashRtn = np.append(cashRtn,np.sum(RedemptionM)/initialVal)\n",
    "\t\tpriceRtn = np.append(priceRtn,(np.sum(MVM)-np.sum(RedemptionM))/initialVal-1)\n",
    "\t\tdefault= np.append(0,thmf[i,[19,21,23,25]])/100\n",
    "\t\tinitialVal = np.sum(MVM)\n",
    "\treturn cashRtn,priceRtn\n",
    "\n",
    "\n",
    "# migrationM = pd.read_csv(migration)\n",
    "# mix=pd.read_csv(termmix)\n",
    "# cashR,priceR = bondReturn(check,mix,migrationM,dyn=60,n=60,rating=4,rebalance=1,bondfreq=1,inter=\"linear\",extro=\"cfr\",expectedRate=0.04)\n",
    "# priceR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add bond fund returns to the stochastic scenarios\n",
    "def AddBondReturn(thmf,mix,migrationM,dyn=10,n=10,rebalance=0,bondfreq=0.25,inter=\"linear\",extro=\"tar\",expectedRate=0.04):\n",
    "\tfor ir in range(0,5):\n",
    "\t\tcashR,priceR = bondReturn(thmf=thmf,mix=mix,migrationM=migrationM,dyn=10,n=n,rating=ir,rebalance=rebalance,bondfreq=bondfreq,inter=inter,extro=extro,expectedRate=expectedRate)\n",
    "\t\tthmf = np.append(thmf,np.transpose(np.vstack([np.insert(cashR,0,0),np.insert(priceR,0,0)])),axis=1)\n",
    "\t\t#print \"rating \", ir, \" done\"\n",
    "\treturn thmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust bond fund returns for periods after dynamic projection time to approximate expected bond fund returns\n",
    "def AdjustBondReturn(thmf,thmfBase,thmfFull,dyn=10,n=10):\n",
    "\tthmf = np.append(thmf,thmfBase[:,range(42,52)],axis=1)\n",
    "\tfor i in range(0,n):\n",
    "\t\tif i> dyn:\n",
    "\t\t\tfor ir in [43,45,47,49,51]:\n",
    "\t\t\t\tthmf[i,ir] = thmfBase[i,ir]+(thmfBase[i,14]-thmfFull[i,14])/400\n",
    "\t\t\tfor ir in [45,47,49,51]:\n",
    "\t\t\t\tthmf[i,ir] = thmfBase[i,ir]+(thmfFull[i,ir-27]-thmfBase[i,ir-27] - thmfFull[i,ir-26]+thmfBase[i,ir-26])/400\n",
    "\treturn thmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Pension Plan Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together with ESG, dynamic projection of asset, liabilty and funding status is performed based on the LDI benchmark model.\n",
    "\n",
    "Dynamic liability projection is computational intensive. All assumptions follow the research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dynamic liability projection assumptions (consistent with research paper)\n",
    "fMI = 0.01 #female mortality improvement\n",
    "mMI = 0.01 #male mortality improvement\n",
    "salaryGr = 0.02 #salary growth rate\n",
    "salaryAvgPeriod = 5 #salary averaging period\n",
    "benefitRate = 0.01 #benefit rate as percentage of averaging salary\n",
    "COLA = 0.8 #portion of cost of living adjustment based on CPI\n",
    "maxCOLA = 0.05 #maximum annual COLA rate\n",
    "lumpSumProb = 0.1 #probabiilty that the benefits are paid as a lump sum\n",
    "lumpSumDR = 0.04 #discount rate used to calculate lump sum\n",
    "valuationDate = date(2016,12,31) #valuation date\n",
    "planliab = 10000000. #initial plan liability\n",
    "\n",
    "#Sample plan participant information\n",
    "#All plan particpant information is stored in file Census\n",
    "dateOfBirth = date(1981,6,30) #date of birth for a sample plan participant\n",
    "startDate = date(2005,1,31) #start date of employment\n",
    "salary = 80000. #current salary\n",
    "retireDate = date(2045,6,30) #expected retirement date\n",
    "weight = 0.08 #weight of the sample plan participant as in the entire pension plan\n",
    "occupation = 4 #occupation type\n",
    "salaryMultiple = np.array([0.9,1.0,1.1,1.2,1.5]) #salary multiple for each occupation type\n",
    "gender = \"F\" #gender of the sample plan participant\n",
    "\n",
    "\n",
    "dyn=10 #dynamic projection time point in quarter\n",
    "inter=\"linear\" #yield curve interpolation method\n",
    "extro=\"tar\" #yield curve extrapolation method\n",
    "target=0.04 #target long term interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate projected benefit obligation for individual plan participant\n",
    "def pbo(gender,dateOfBirth, startDate,retireDate,salary,occupation,weight,thmf,dyn,inter=\"linear\",extro=\"tar\",target=0.04):\n",
    "\twTerms = int(max(0,(retireDate.year - valuationDate.year)*4+(retireDate.month-valuationDate.month)/4))+1\n",
    "\tretireArray = np.repeat(0,wTerms)\n",
    "\tretireArray = np.append(retireArray,np.repeat(1,361-wTerms))\n",
    "\tservicePeriod = (valuationDate.year - startDate.year) + (valuationDate.month - startDate.month)/12.\n",
    "\tspArray = np.repeat(servicePeriod,361)\n",
    "\tage = (valuationDate.year - dateOfBirth.year) + (valuationDate.month - startDate.month)/12.\n",
    "\tageArray = np.repeat(age,361)\n",
    "\tqScn = thmf.shape[0]-1\n",
    "\twageIndex = np.repeat(1.,361)\n",
    "\tCOLAArray = np.repeat(1.,361)\n",
    "\tsalaryArray = np.repeat(salary,361)\n",
    "\tsupSalaryArray = np.repeat(salary,361+salaryAvgPeriod*4-1)\n",
    "\tfor i in range(0,salaryAvgPeriod*4-1):\n",
    "\t\tif i%4 == 0:\n",
    "\t\t\tsupSalaryArray[i] = salary/(1+salaryGr*salaryMultiple[occupation-1])**(salaryAvgPeriod-1-i/4)\n",
    "\t\telse:\n",
    "\t\t\tsupSalaryArray[i] = supSalaryArray[i-1]\n",
    "\tavgSalaryArray = np.repeat(np.average(supSalaryArray[0:salaryAvgPeriod*4]),361)\n",
    "\taccBenefitArray = np.repeat(0.,361)\n",
    "\tprjBenefitArray = np.repeat(0.,361)\n",
    "\tpaymentArray = np.repeat(0.,361)\n",
    "\tprjPaymentArray = np.repeat(0.,361)\n",
    "\n",
    "\tmortTables = pd.read_csv(Mortality)\n",
    "\tmortTables = np.array(mortTables)\n",
    "\tif gender == \"M\":\n",
    "\t\tbaseMortArray = np.repeat(1-(1-mortTables[min(110,int(round(age))),1])**0.25,361)\n",
    "\telse:\n",
    "\t\tbaseMortArray = np.repeat(1-(1-mortTables[min(110,int(round(age))),2])**0.25,361)\n",
    "\n",
    "\tsurvivorship = np.repeat(1.,361)\n",
    "\n",
    "\tldrArray = np.repeat(1.,361)\n",
    "\tpcdrArray = np.repeat(1.,361)\n",
    "\tlsdrArray = np.repeat(1.,361)\n",
    "\n",
    "\tvalue = thmf[dyn,[4,9,10,11,12,13,14,15,16]]\n",
    "\tvalue = value + thmf[dyn,20]\n",
    "\txi,yi = curvefitting(value/100,term=np.array([0.25,1,2,3,5,7,10,20,30]),inter=inter,extro=extro,target=target)\n",
    "\n",
    "\tfor t in range(1,361):\n",
    "\n",
    "\t\tif retireArray[t] == 1:\n",
    "\t\t\tspArray[t] = spArray[t-1]\n",
    "\t\telse:\n",
    "\t\t\tspArray[t] = servicePeriod + t/4.\n",
    "\n",
    "\t\tageArray[t] = age + t/4.\n",
    "\n",
    "\t\tif retireArray[t] == 1:\n",
    "\t\t\twageIndex[t] = wageIndex[t-1]\n",
    "\t\telif t%4 == 0:\n",
    "\t\t\twageIndex[t] = wageIndex[t-1]*(1+((1+thmf[min(t,qScn),38]/100)*(1+thmf[min(t-1,qScn),38]/100)*(1+thmf[min(t-2,qScn),38]/100)*(1+thmf[min(t-3,qScn),38]/100)-1)*salaryMultiple[occupation-1])\n",
    "\t\telse:\n",
    "\t\t\twageIndex[t] = wageIndex[t-1]\n",
    "\n",
    "\t\tif retireArray[t] == 0:\n",
    "\t\t\tCOLAArray[t] = 1\n",
    "\t\telif t%4 == 0:\n",
    "\t\t\tCOLAArray[t] = COLAArray[t-1] * min(1+maxCOLA,(1-COLA)+COLA*(1+thmf[min(t,qScn),17]/100)*(1+thmf[min(t-1,qScn),17]/100)*(1+thmf[min(t-2,qScn),17]/100)*(1+thmf[min(t-3,qScn),17]/100))\n",
    "\t\telse:\n",
    "\t\t\tCOLAArray[t] = COLAArray[t-1]\n",
    "\n",
    "\t\tif retireArray[t] == 0:\n",
    "\t\t\tsalaryArray[t] = salary * wageIndex[t]\n",
    "\t\t\tsupSalaryArray[t+salaryAvgPeriod*4-1] = salaryArray[t]\n",
    "\t\telse:\n",
    "\t\t\tsalaryArray[t] = salaryArray[t-1]\n",
    "\t\t\tsupSalaryArray[t+salaryAvgPeriod*4-1] = salaryArray[t]\n",
    "\n",
    "\t\tavgSalaryArray[t] = np.average(supSalaryArray[t:(t+salaryAvgPeriod*4)])\n",
    "\n",
    "\t\taccBenefitArray[t] = avgSalaryArray[t]*benefitRate*min(servicePeriod+dyn/4.,spArray[t])*COLAArray[t]/4\n",
    "\t\tprjBenefitArray[t] = avgSalaryArray[t]*benefitRate*spArray[t]*COLAArray[t]/4\n",
    "\n",
    "\t\tif gender == \"M\":\n",
    "\t\t\tbaseMortArray[t] = 1-(1-mortTables[min(110,int(round(ageArray[t]))),1])**0.25\n",
    "\t\t\tsurvivorship[t] = survivorship[t-1]*(1-baseMortArray[t]*(1-mMI))\n",
    "\t\telse:\n",
    "\t\t\tbaseMortArray[t] = 1-(1-mortTables[min(110,int(round(ageArray[t]))),2])**0.25\n",
    "\t\t\tsurvivorship[t] = survivorship[t-1]*(1-baseMortArray[t]*(1-fMI))\n",
    "\n",
    "\t\tlsdrArray[t] = lsdrArray[t-1]/(1+lumpSumDR)**0.25\n",
    "\t\tmt = thmf.shape[0]-1\n",
    "\t\tif t <dyn:\n",
    "\t\t\tldrArray[t] = 1\n",
    "\t\t\tpcdrArray[t] = 1\n",
    "\t\telse:\n",
    "\t\t\tldrArray[t] = ldrArray[t-1]/(1+yi[t-dyn])**0.25\n",
    "\n",
    "\tlumpSum = np.sum(np.multiply(np.multiply(np.multiply(lsdrArray,accBenefitArray),survivorship),retireArray))/lsdrArray[wTerms]/survivorship[wTerms]\n",
    "\tfor t in range(1,361):\n",
    "\t\tif wTerms == 0:\n",
    "\t\t\tpaymentArray[t] = accBenefitArray[t]*retireArray[t]*survivorship[t]\n",
    "\t\t\tprjPaymentArray[t] = prjBenefitArray[t]*retireArray[t]*survivorship[t]\n",
    "\t\telif t == wTerms:\n",
    "\t\t\tpaymentArray[t] = accBenefitArray[t]*retireArray[t]*survivorship[t]*(1-lumpSumProb)+lumpSum*lumpSumProb\n",
    "\t\t\tprjPaymentArray[t] = prjBenefitArray[t]*retireArray[t]*survivorship[t]\n",
    "\t\telse:\n",
    "\t\t\tpaymentArray[t] = accBenefitArray[t]*retireArray[t]*survivorship[t]*(1-lumpSumProb)\n",
    "\t\t\tprjPaymentArray[t] = prjBenefitArray[t]*retireArray[t]*survivorship[t]\n",
    "\tdynArray = np.repeat(0,361)\n",
    "\tfor t in range(0,361):\n",
    "\t\tif t > dyn:\n",
    "\t\t\tdynArray[t]=1\n",
    "\n",
    "\tdynPBO = np.sum(np.multiply(np.multiply(paymentArray,ldrArray),dynArray))/survivorship[dyn]\n",
    "\tif retireArray[dyn]==0:\n",
    "\t\tplanCost = 0.25/max(spArray)*np.sum(np.multiply(prjPaymentArray,pcdrArray))/survivorship[dyn]\n",
    "\telse:\n",
    "\t\tplanCost = 0\n",
    "\treturn [dynPBO,planCost,paymentArray[dyn],prjPaymentArray[dyn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.230445964671105\n"
     ]
    }
   ],
   "source": [
    "employees = pd.read_csv(Census)\n",
    "\n",
    "#Calculate initial liabilty multiple to match initial plan liability\n",
    "def liabMultiple(employees,thmf,planliab=10000000.,inter=\"linear\",extro=\"tar\",target=0.04):\n",
    "\tliabSum = 0\n",
    "\temployees = np.array(employees)\n",
    "\tfor employID in range(0,employees.shape[0]):\n",
    "\t\tgender=employees[employID,2]\n",
    "\t\tdateOfBirth=date(*map(int, employees[employID,3].split('-')))\n",
    "\t\tstartDate=date(*map(int, employees[employID,4].split('-')))\n",
    "\t\tretireDate=date(*map(int, employees[employID,6].split('-')))\n",
    "\t\tsalary=employees[employID,5]\n",
    "\t\toccupation=employees[employID,7]\n",
    "\t\tweight=employees[employID,8]\n",
    "\t\twTerms = int(max(0,(retireDate.year - valuationDate.year)*4+(retireDate.month-valuationDate.month)/4))+1\n",
    "\t\tretireArray = np.repeat(0,wTerms)\n",
    "\t\tretireArray = np.append(retireArray,np.repeat(1,361-wTerms))\n",
    "\t\tservicePeriod = (valuationDate.year - startDate.year) + (valuationDate.month - startDate.month)/12.\n",
    "\t\tspArray = np.repeat(servicePeriod,361)\n",
    "\t\tage = (valuationDate.year - dateOfBirth.year) + (valuationDate.month - startDate.month)/12.\n",
    "\t\tageArray = np.repeat(age,361)\n",
    "\t\tqScn = thmf.shape[0]-1\n",
    "\t\twageIndex = np.repeat(1.,361)\n",
    "\t\tCOLAArray = np.repeat(1.,361)\n",
    "\t\tsalaryArray = np.repeat(salary,361)\n",
    "\t\tsupSalaryArray = np.repeat(salary,361+salaryAvgPeriod*4-1)\n",
    "\t\tfor i in range(0,salaryAvgPeriod*4-1):\n",
    "\t\t\tif i%4 == 0:\n",
    "\t\t\t\tsupSalaryArray[i] = salary/(1+salaryGr*salaryMultiple[occupation-1])**(salaryAvgPeriod-1-i/4)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsupSalaryArray[i] = supSalaryArray[i-1]\n",
    "\t\tavgSalaryArray = np.repeat(np.average(supSalaryArray[0:salaryAvgPeriod*4]),361)\n",
    "\t\taccBenefitArray = np.repeat(0.,361)\n",
    "\t\tpaymentArray = np.repeat(0.,361)\n",
    "\n",
    "\t\tmortTables = pd.read_csv(Mortality)\n",
    "\t\tmortTables = np.array(mortTables)\n",
    "\t\tif gender == \"M\":\n",
    "\t\t\tbaseMortArray = np.repeat(1-(1-mortTables[min(110,int(round(age))),1])**0.25,361)\n",
    "\t\telse:\n",
    "\t\t\tbaseMortArray = np.repeat(1-(1-mortTables[min(110,int(round(age))),2])**0.25,361)\n",
    "\n",
    "\t\tsurvivorship = np.repeat(1.,361)\n",
    "\n",
    "\t\tldrArray = np.repeat(1.,361)\n",
    "\t\tlsdrArray = np.repeat(1.,361)\n",
    "\n",
    "\t\tvalue = thmf[0,[4,9,10,11,12,13,14,15,16]]\n",
    "\t\tvalue = value + thmf[0,20]\n",
    "\t\txi,yi = curvefitting(value/100,term=np.array([0.25,1,2,3,5,7,10,20,30]),inter=inter,extro=extro,target=target)\n",
    "\n",
    "\t\tfor t in range(1,361):\n",
    "\n",
    "\t\t\tif retireArray[t] == 1:\n",
    "\t\t\t\tspArray[t] = spArray[t-1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tspArray[t] = servicePeriod + t/4.\n",
    "\n",
    "\t\t\tageArray[t] = age + t/4.\n",
    "\n",
    "\t\t\tif retireArray[t] == 1:\n",
    "\t\t\t\twageIndex[t] = wageIndex[t-1]\n",
    "\t\t\telif t%4 == 0:\n",
    "\t\t\t\twageIndex[t] = wageIndex[t-1]*(1+((1+thmf[min(t,qScn),38]/100)*(1+thmf[min(t-1,qScn),38]/100)*(1+thmf[min(t-2,qScn),38]/100)*(1+thmf[min(t-3,qScn),38]/100)-1)*salaryMultiple[occupation-1])\n",
    "\t\t\telse:\n",
    "\t\t\t\twageIndex[t] = wageIndex[t-1]\n",
    "\n",
    "\t\t\tif retireArray[t] == 0:\n",
    "\t\t\t\tCOLAArray[t] = 1\n",
    "\t\t\telif t%4 == 0:\n",
    "\t\t\t\tCOLAArray[t] = COLAArray[t-1] * min(1+maxCOLA,(1-COLA)+COLA*(1+thmf[min(t,qScn),17]/100)*(1+thmf[min(t-1,qScn),17]/100)*(1+thmf[min(t-2,qScn),17]/100)*(1+thmf[min(t-3,qScn),17]/100))\n",
    "\t\t\telse:\n",
    "\t\t\t\tCOLAArray[t] = COLAArray[t-1]\n",
    "\n",
    "\t\t\tif retireArray[t] == 0:\n",
    "\t\t\t\tsalaryArray[t] = salary * wageIndex[t]\n",
    "\t\t\t\tsupSalaryArray[t+salaryAvgPeriod*4-1] = salaryArray[t]\n",
    "\t\t\telse:\n",
    "\t\t\t\tsalaryArray[t] = salaryArray[t-1]\n",
    "\t\t\t\tsupSalaryArray[t+salaryAvgPeriod*4-1] = salaryArray[t]\n",
    "\n",
    "\t\t\tavgSalaryArray[t] = np.average(supSalaryArray[t:(t+salaryAvgPeriod*4)])\n",
    "\n",
    "\t\t\taccBenefitArray[t] = avgSalaryArray[t]*benefitRate*servicePeriod*COLAArray[t]/4\n",
    "\n",
    "\t\t\tif gender == \"M\":\n",
    "\t\t\t\tbaseMortArray[t] = 1-(1-mortTables[min(110,int(round(ageArray[t]))),1])**0.25\n",
    "\t\t\t\tsurvivorship[t] = survivorship[t-1]*(1-baseMortArray[t]*(1-mMI))\n",
    "\t\t\telse:\n",
    "\t\t\t\tbaseMortArray[t] = 1-(1-mortTables[min(110,int(round(ageArray[t]))),2])**0.25\n",
    "\t\t\t\tsurvivorship[t] = survivorship[t-1]*(1-baseMortArray[t]*(1-fMI))\n",
    "\n",
    "\t\t\n",
    "\t\t\tlsdrArray[t] = lsdrArray[t-1]/(1+lumpSumDR)**0.25\n",
    "\t\t\tldrArray[t] = ldrArray[t-1]/(1+yi[t])**0.25\n",
    "\t\n",
    "\t\tlumpSum = np.sum(np.multiply(np.multiply(np.multiply(lsdrArray,accBenefitArray),survivorship),retireArray))/lsdrArray[wTerms]/survivorship[wTerms]\n",
    "\t\tfor t in range(1,361):\n",
    "\t\t\tif wTerms == 0:\n",
    "\t\t\t\tpaymentArray[t] = accBenefitArray[t]*retireArray[t]*survivorship[t]\n",
    "\t\t\telif t == wTerms:\n",
    "\t\t\t\tpaymentArray[t] = accBenefitArray[t]*retireArray[t]*survivorship[t]*(1-lumpSumProb)+lumpSum*lumpSumProb\n",
    "\t\t\telse:\n",
    "\t\t\t\tpaymentArray[t] = accBenefitArray[t]*retireArray[t]*survivorship[t]*(1-lumpSumProb)\n",
    "\n",
    "\t\tdynPBO = np.sum(np.multiply(paymentArray,ldrArray))\n",
    "\t\t#if employID==8:\n",
    "\t\t\t#print accBenefitArray,paymentArray\n",
    "\t\tliabSum = liabSum + dynPBO*weight\n",
    "\t\t#print(dynPBO, weight)\n",
    "\tmultiple = planliab/liabSum\n",
    "\treturn multiple\n",
    "\n",
    "check = sampleMF(var,fundmap,hmf,har,var1chol,normalChol,recessionChol,60,60,stochastic=False)\n",
    "multiple = liabMultiple(employees,check,planliab,inter,extro,target)\n",
    "print(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated projected benefit obligation for all plan participants by matching initial plan liability.\n",
    "def aggPBO(employees,thmf,dyn,multiple,planliab=10000000.,inter=\"linear\",extro=\"tar\",target=0.04):\n",
    "\taggResult = np.array([0,0,0,0])\n",
    "\temployees = np.array(employees)\n",
    "\t#multiple = liabMultiple(employees,thmf,planliab,inter,extro,target)\n",
    "#\tprint multiple\n",
    "\tfor employID in range(0,employees.shape[0]):\n",
    "\t\tgender=employees[employID,2]\n",
    "\t\tdateOfBirth=date(*map(int, employees[employID,3].split('-')))\n",
    "\t\tstartDate=date(*map(int, employees[employID,4].split('-')))\n",
    "\t\tretireDate=date(*map(int, employees[employID,6].split('-')))\n",
    "\t\tsalary=employees[employID,5]\n",
    "\t\toccupation=employees[employID,7]\n",
    "\t\tweight=employees[employID,8]\n",
    "#\t\tprint weight\n",
    "\t\taggResult = aggResult + np.multiply(weight, np.array(pbo(gender,dateOfBirth, startDate,retireDate,salary,occupation,weight,thmf,dyn,inter,extro,target)))\n",
    "#\t\tprint(weight,np.array(pbo(gender,dateOfBirth, startDate,retireDate,salary,occupation,weight,thmf,dyn,inter,extro,target)))\n",
    "\taggResult = np.multiply(aggResult, multiple)\n",
    "\treturn aggResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic asset projection assumption\n",
    "nsim = 1 #number of simulations\n",
    "ndyn = 60 #numbr of dynamic periods in quarter\n",
    "max_period = 40 #maximum number of periods for projection\n",
    "planasset = 10000000.*1.0 #initial plan asset\n",
    "\n",
    "saa=[0.5,0.5] #sample asset allocation (AA-rated bond, large scale public equity)\n",
    "rebalance = 0.25\n",
    "bondfreq = 0.25 #bond coupon frequency in bond fund calculation\n",
    "expectedRate = 0.04 #expected long term interest rate\n",
    "bs = True #rebalance or not\n",
    "possaa = saa #reinvestment mix for positive cash flow\n",
    "negsaa = saa #deinvestment mix for negative cash flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simulations with scenarios and asset liability projection to be used for reinforcement learning\n",
    "#Each simulation will take about 8 mins to finish including bond fund return calculation and dynamic liability projection\n",
    "#for 40 quarters. Parallel computing is needed for \n",
    "def createStates(nsim,ndyn,var,fundmap,histMF,histAR,cholMF,\\\n",
    "\t\t\tcholNormal,cholRecession,mix,migrationM,stochastic=True,\\\n",
    "\t\t\tinter=\"linear\",extro=\"tar\",target=0.04,rebalance=0.5,bondfreq=0.25):\n",
    "\tthmf=sampleMF(var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,0,1,stochastic=False)\n",
    "\tthmfBase=sampleMF(var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,ndyn,ndyn,stochastic=False)\n",
    "\tthmfBase=AddBondReturn(thmfBase,mix,migrationM,ndyn,ndyn,rebalance,bondfreq,inter,extro,expectedRate)\n",
    "\ttmpArray = np.copy(thmfBase)\n",
    "\t\n",
    "\tfor isim in range(0,nsim):\n",
    "\t\tprint(\"Starting Simulation \", isim+1, \": \", str(datetime.now()))\n",
    "\t\tdynThmf=sampleMF(var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,ndyn,ndyn,stochastic)\n",
    "\t\tthmfFull=AddBondReturn(dynThmf,mix,migrationM,ndyn,ndyn,rebalance,bondfreq,inter,extro,expectedRate)\n",
    "\t\ttmpArray = np.vstack([tmpArray,thmfFull])\n",
    "\t\tprint(\"Finishing Simulation \", isim+1, \": \", str(datetime.now()))\n",
    "\treturn tmpArray\n",
    "\n",
    "# import random\n",
    "# random.seed(123)\n",
    "# mix=pd.read_csv(termmix)\n",
    "# migrationM = pd.read_csv(migration)\n",
    "# tmpArrays = createStates(nsim,ndyn,var,fundmap,hmf,har,var1chol,normalChol,recessionChol, \\\n",
    "# \t\t\tmix,migrationM,stochastic=True, \\\n",
    "# \t\t\tinter=\"linear\",extro=\"tar\",target=0.04,rebalance=0.25,bondfreq=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61061, 52)\n"
     ]
    }
   ],
   "source": [
    "#Pregenerated 1000 simulations\n",
    "tmpArrays=np.array(pd.read_csv(\"C:/dsge/py/input/test_states.csv\",header=None))\n",
    "print(tmpArrays.shape)\n",
    "#It includes 1001 simulations with the first one the static one without any volatility\n",
    "#Each simulation has 61 rows that is 15 years' quarterly projection.\n",
    "#52 modeled variables including economic factors, TB yield curve, credit spreads and default rate, asset returns, and bond fund returns\n",
    "#Variable names listed below and are consistent with the LDI benchmark model\n",
    "\n",
    "#gdpgr\n",
    "#pconsump\n",
    "#cpi\n",
    "#Unemploy\n",
    "#m3tb\n",
    "#tb10y\n",
    "#aa10y\n",
    "#gpdinv\n",
    "#Recession\n",
    "#tb1y\n",
    "#tb2y\n",
    "#tb3y\n",
    "#tb5y\n",
    "#tb7y\n",
    "#tb10y\n",
    "#tb20y\n",
    "#tb30y\n",
    "#cpi\n",
    "#aaaboa\n",
    "#aaadefault\n",
    "#aaboa\n",
    "#aadefault\n",
    "#aboa\n",
    "#adefault\n",
    "#bbbboa\n",
    "#bbbdefault\n",
    "#sp500d\n",
    "#sp500\n",
    "#spmidd\n",
    "#spmid\n",
    "#spsmalld\n",
    "#spsmall\n",
    "#spdivd\n",
    "#spdiv\n",
    "#ereitinc\n",
    "#ereit\n",
    "#mreitinc\n",
    "#mreitret\n",
    "#wage\n",
    "#Unemploy\n",
    "#gdpgr\n",
    "#sponsor\n",
    "#gb_cr\n",
    "#gb_pr\n",
    "#aaa_cr\n",
    "#aaa_pr\n",
    "#aa_cr\n",
    "#aa_pr\n",
    "#a_cr\n",
    "#a_pr\n",
    "#bbb_cr\n",
    "#bbb_pr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add liability valuation results for each simulation. Each simulation will take around 9 seconds.\n",
    "# counter = 0\n",
    "# thmfBase=tmpArrays[0:(ndyn+1),]\n",
    "# for sim in range(1,2):\n",
    "#     dynThmf=tmpArrays[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),0:42]\n",
    "#     thmfFull=tmpArrays[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:]\n",
    "#     for iq in range(1,ndyn+1):\n",
    "#         thmf = sampleMF2(dynThmf, var,fundmap,hmf,har,var1chol,normalChol,recessionChol,iq,ndyn)\n",
    "#         thmf = AdjustBondReturn(thmf,thmfBase,thmfFull,iq,ndyn)\n",
    "#         pboArray = aggPBO(employees,thmf,iq,multiple,planliab,inter,extro,target)#dyn\n",
    "#         liabNCF = pboArray[1] - pboArray[2]\n",
    "#         pboArray = np.append(pboArray, liabNCF)\n",
    "#         if counter == 0:\n",
    "#             liabAll = pboArray\n",
    "#         else:\n",
    "#             liabAll = np.vstack([liabAll,pboArray])\n",
    "#         counter = counter + 1\n",
    "#     print(\"Liability valuation for simulation \", sim, \" is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pregenerated liabiltiy projection for 1000 stochastic simulations\n",
    "liabAll=np.array(pd.read_csv(\"C:/dsge/py/input/liab.csv\",header=None))\n",
    "#each simulation contains 60 rows which represents 60 end of quarter values\n",
    "#Five variables: \n",
    "#liabilty value\n",
    "#plan cost/plan contribution\n",
    "#accrued benefit payment\n",
    "#projected benefit payment\n",
    "#liabilty net cash flow (plan cost - accrued benefit payment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains 4 subsections:\n",
    "\n",
    "RL1: LSTM model with rebalance constraints\n",
    "\n",
    "RL2: LSTM model without rebalance constraints\n",
    "\n",
    "RL3: FCNN model with rebalance constraints\n",
    "\n",
    "RL4: FCNN model without rebalance constraints\n",
    "\n",
    "Each subsection includes deep learning model inputs, reward function, deep learning model setting, model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL1: LSTM model with rebalance constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get inputs for LSTM models\n",
    "def getLSTMState(employees,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,sim,dyn):\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [8]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    lists = [max(0,dyn-1), dyn]\n",
    "    counter = 0\n",
    "    for i in lists:\n",
    "        inewState = thmf[i,:].flatten()\n",
    "        asset_alloc = liabArray[6:8]/np.sum(liabArray[6:8])\n",
    "        inewState = np.append(inewState,asset_alloc)\n",
    "        inewState = np.append(inewState,i)#let's add time\n",
    "        inewState = np.append(inewState,np.sum(liabArray[6:8])/liabArray[2])#let's add time 6:17\n",
    "        if counter == 0:\n",
    "            newState = inewState\n",
    "        else:\n",
    "            newState = np.vstack((newState, inewState))\n",
    "        \n",
    "        counter = counter + 1\n",
    "    return newState\n",
    "\n",
    "# liabArray = np.array([1,0,planliab,0,0,0])\n",
    "# liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "# liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "# state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "#             liabArray,tmpArrays,5,5)\n",
    "# print(state.shape, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_multiple = 1.0\n",
    "#get current reward\n",
    "def getReward(employees, saa, action,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,liabAll,sim,dyn,multiple,planliab=10000000.,bs = True,\\\n",
    "            inter=\"linear\",extro=\"tar\",target=0.04):\n",
    "    \n",
    "    assetArray = liabArray[6:8]\n",
    "    if action==0: #keep current mix\n",
    "        csaa = saa\n",
    "    elif action == 1: #increase bond investment\n",
    "        csaa = np.minimum(1,np.maximum(0,saa + np.array([0.02,-0.02])))\n",
    "    else: #decrease bond investment\n",
    "        csaa = np.minimum(1,np.maximum(0,saa + np.array([-0.02,0.02])))\n",
    "\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [0,1,2,3,4,5,6,7,8,26,27,46,47]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    pboArray = liabAll[((sim-1)*ndyn+iq-1),0:4]\n",
    "    liabNCF = pboArray[1] - pboArray[2]\n",
    "    cashRtns = np.array([thmf[iq,11],thmf[iq,9]/4])\n",
    "    priceRtns = np.array([thmf[iq,12],thmf[iq,10]])\n",
    "    cashCF = np.sum(np.multiply(assetArray,cashRtns/100))\n",
    "    assetArray = assetArray+np.multiply(assetArray,priceRtns/100)\n",
    "    newAssetValue = np.sum(assetArray)\n",
    "    if bs == False and (cashCF+liabNCF) > 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    elif bs == False and (cashCF + liabNCF) <= 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    else:\n",
    "        bsArray = np.multiply((cashCF+liabNCF+newAssetValue),csaa)-assetArray\n",
    "    assetArray = assetArray + bsArray\n",
    "    pboArray = np.insert(pboArray,0,[sim,iq])\n",
    "    pboArray = np.append(pboArray,assetArray)\n",
    "    pboArray = np.append(pboArray,np.array([np.sum(assetArray),np.sum(assetArray)/pboArray[2],np.sum(assetArray)-pboArray[2]]))\n",
    "    reward = - np.sum(liabArray[6:8])/liabArray[2] + np.sum(pboArray[6:8])/pboArray[2]#reward is change in funding ratio\n",
    "    if reward < 0: reward = neg_multiple*reward    \n",
    "    return reward,pboArray,csaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define deep learning model to approximate reward function\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False #if False, CPU is used\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(5,64)\n",
    "        self.lin1 = nn.Linear(64, 256)\n",
    "        self.lin2 = nn.Linear(256, 64)\n",
    "        self.lin3 = nn.Linear(64, 32)\n",
    "        self.lin4 = nn.Linear(32, 16)\n",
    "        self.head = nn.Linear(16, 3)\n",
    "        self.hidden = self.init_hidden(100)\n",
    "        self.fixhidden = self.init_hidden(100)\n",
    "\n",
    "    def init_hidden(self, size):\n",
    "        return (Variable(torch.randn((1, size, 64))),Variable(torch.randn((1, size, 64))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(2,-1,5)\n",
    "        self.hidden = self.init_hidden(x.size(1))\n",
    "        nperiod = x.size(0)\n",
    "        lstm_out, self.hidden = self.lstm1(x, self.hidden)\n",
    "        x = torch.relu(lstm_out[nperiod-1])\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "        x = torch.relu(self.lin3(x))\n",
    "        x = torch.relu(self.lin4(x))\n",
    "        return self.head(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL specification\n",
    "BATCH_SIZE = 1000\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.75\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = max(1000, BATCH_SIZE)\n",
    "STATIC_UPDATE = 10 #update frequency\n",
    "\n",
    "model = DQN()\n",
    "static_model = DQN()\n",
    "static_model.load_state_dict(model.state_dict())\n",
    "static_model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "memory = ReplayMemory(400000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state, counter):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold and counter > BATCH_SIZE:\n",
    "        with torch.no_grad():\n",
    "            return model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(3)]])\n",
    "\n",
    "last_sync = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    global last_sync\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return 0.0, 0.0\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = model(state_batch.type(FloatTensor)).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE).type(Tensor)\n",
    "    next_state_values[non_final_mask] = static_model(non_final_next_states.type(FloatTensor)).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    loss = F.mse_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    return float(loss), float(torch.mean(expected_state_action_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  10\n",
      "Episode:  20\n",
      "Episode:  30\n",
      "Episode:  40\n",
      "Episode:  50\n",
      "Episode:  60\n",
      "Episode:  70\n",
      "Episode:  80\n",
      "Episode:  90\n",
      "Episode:  100\n",
      "Complete\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_episodes = 100 #how many episodes to be used for training. If # of episodes > # of sims, data will be repetitively used for training\n",
    "num_sims = 800 #how many simulations to be used for training\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "\n",
    "counter = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    if (i_episode+1)% num_sims == 0:\n",
    "        isim = num_sims\n",
    "    else:\n",
    "        isim = (i_episode+1)% num_sims\n",
    "    state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,isim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(-1,5)\n",
    "    for idyn in range(1,41):\n",
    "        counter = counter + 1\n",
    "        action = select_action(state, counter)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,isim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,isim,idyn) #+1\n",
    "            next_state = torch.from_numpy(next_state).view(-1,5)\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "\n",
    "        loss, val =optimize_model()\n",
    "    if i_episode % 10 == 9:\n",
    "        print(\"Episode: \",i_episode+1)\n",
    "    if i_episode % STATIC_UPDATE == 0:\n",
    "        static_model.load_state_dict(model.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation:  50\n",
      "Simulation:  100\n",
      "Simulation:  150\n",
      "Simulation:  200\n",
      "Simulation:  250\n",
      "Simulation:  300\n",
      "Simulation:  350\n",
      "Simulation:  400\n",
      "Simulation:  450\n",
      "Simulation:  500\n",
      "Simulation:  550\n",
      "Simulation:  600\n",
      "Simulation:  650\n",
      "Simulation:  700\n",
      "Simulation:  750\n",
      "Simulation:  800\n",
      "Simulation:  850\n",
      "Simulation:  900\n",
      "Simulation:  950\n",
      "Simulation:  1000\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "def select_best_action(state):\n",
    "    with torch.no_grad():\n",
    "        return static_model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "\n",
    "#Evaluate the model\n",
    "num_sims = 1000\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "sims = []\n",
    "sims_sim = []\n",
    "qs = []\n",
    "rwds = []\n",
    "rwds_total = []\n",
    "\n",
    "num_sims\n",
    "\n",
    "for i_sim in range(1,num_sims+1):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,i_sim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(-1,5)\n",
    "    reward_total = 0\n",
    "    for idyn in range(1,41):\n",
    "        # Select and perform an action\n",
    "        action = select_best_action(state)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,i_sim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        reward_total = reward_total + reward * GAMMA**(idyn-1)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,i_sim,idyn)#+1\n",
    "            next_state = torch.from_numpy(next_state).view(-1,5)\n",
    "        state = next_state\n",
    "\n",
    "        sims.append(i_sim+1)\n",
    "        qs.append(idyn+1)\n",
    "        rwds.append(float(reward))\n",
    "    rwds_total.append(reward_total)\n",
    "    sims_sim.append(i_sim)\n",
    "    if i_sim % 50 == 49:\n",
    "        print(\"Simulation: \",i_sim+1)\n",
    "\n",
    "df = pd.DataFrame(tliabArray)\n",
    "df.to_csv('C:/dsge/py/output/lstm_w_constraint_results_'+str(neg_multiple)+str(GAMMA)+'_'+str(BATCH_SIZE)+'_'+str(num_sims)+'.csv')\n",
    "#Output file has the following variables\n",
    "#id\n",
    "#scn\n",
    "#period\n",
    "#liability value\n",
    "#plan cost\n",
    "#accured benefit payment\n",
    "#projected benefit payment\n",
    "#AA-rated bond investment\n",
    "#public equity investment\n",
    "#total asset value\n",
    "#funding ratio\n",
    "#funding surplus\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL2: LSTM model without rebalance constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get inputs for LSTM models\n",
    "def getLSTMState(employees,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,sim,dyn):\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [8]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    lists = [max(0,dyn-1), dyn]\n",
    "    counter = 0\n",
    "    for i in lists:\n",
    "        inewState = thmf[i,:].flatten()\n",
    "        asset_alloc = liabArray[6:8]/np.sum(liabArray[6:8])\n",
    "        inewState = np.append(inewState,asset_alloc)\n",
    "        inewState = np.append(inewState,i)#let's add time\n",
    "        inewState = np.append(inewState,np.sum(liabArray[6:8])/liabArray[2])#let's add time 6:17\n",
    "        if counter == 0:\n",
    "            newState = inewState\n",
    "        else:\n",
    "            newState = np.vstack((newState, inewState))\n",
    "        \n",
    "        counter = counter + 1\n",
    "    return newState\n",
    "\n",
    "# liabArray = np.array([1,0,planliab,0,0,0])\n",
    "# liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "# liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "# state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "#             liabArray,tmpArrays,5,5)\n",
    "# print(state.shape, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_multiple = 1.0\n",
    "#get current reward\n",
    "def getReward(employees, saa, action,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,liabAll,sim,dyn,multiple,planliab=10000000.,bs = True,\\\n",
    "            inter=\"linear\",extro=\"tar\",target=0.04):\n",
    "    \n",
    "    assetArray = liabArray[6:8]\n",
    "    csaa=np.array([0.02*action.item(),1-0.02*action.item()]) #select from 51 asset allocation plans\n",
    "\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [0,1,2,3,4,5,6,7,8,26,27,46,47]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    pboArray = liabAll[((sim-1)*ndyn+iq-1),0:4]\n",
    "    liabNCF = pboArray[1] - pboArray[2]\n",
    "    cashRtns = np.array([thmf[iq,11],thmf[iq,9]/4])\n",
    "    priceRtns = np.array([thmf[iq,12],thmf[iq,10]])\n",
    "    cashCF = np.sum(np.multiply(assetArray,cashRtns/100))\n",
    "    assetArray = assetArray+np.multiply(assetArray,priceRtns/100)\n",
    "    newAssetValue = np.sum(assetArray)\n",
    "    if bs == False and (cashCF+liabNCF) > 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    elif bs == False and (cashCF + liabNCF) <= 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    else:\n",
    "        bsArray = np.multiply((cashCF+liabNCF+newAssetValue),csaa)-assetArray\n",
    "    assetArray = assetArray + bsArray\n",
    "    pboArray = np.insert(pboArray,0,[sim,iq])\n",
    "    pboArray = np.append(pboArray,assetArray)\n",
    "    pboArray = np.append(pboArray,np.array([np.sum(assetArray),np.sum(assetArray)/pboArray[2],np.sum(assetArray)-pboArray[2]]))\n",
    "    reward = - np.sum(liabArray[6:8])/liabArray[2] + np.sum(pboArray[6:8])/pboArray[2]#reward is change in funding ratio\n",
    "    if reward < 0: reward = neg_multiple*reward    \n",
    "    return reward,pboArray,csaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define deep learning model to approximate reward function\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False #if False, CPU is used\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(5,64)\n",
    "        self.lin1 = nn.Linear(64, 256)\n",
    "        self.lin2 = nn.Linear(256, 64)\n",
    "        self.lin3 = nn.Linear(64, 32)\n",
    "        self.lin4 = nn.Linear(32, 16)\n",
    "        self.head = nn.Linear(16, 51)\n",
    "        self.hidden = self.init_hidden(100)\n",
    "        self.fixhidden = self.init_hidden(100)\n",
    "\n",
    "    def init_hidden(self, size):\n",
    "        return (Variable(torch.randn((1, size, 64))),Variable(torch.randn((1, size, 64))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(2,-1,5)\n",
    "        self.hidden = self.init_hidden(x.size(1))\n",
    "        nperiod = x.size(0)\n",
    "        lstm_out, self.hidden = self.lstm1(x, self.hidden)\n",
    "        x = torch.relu(lstm_out[nperiod-1])\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "        x = torch.relu(self.lin3(x))\n",
    "        x = torch.relu(self.lin4(x))\n",
    "        return self.head(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL specification\n",
    "BATCH_SIZE = 1000\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.75\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = max(1000, BATCH_SIZE)\n",
    "STATIC_UPDATE = 10 #update frequency\n",
    "\n",
    "model = DQN()\n",
    "static_model = DQN()\n",
    "static_model.load_state_dict(model.state_dict())\n",
    "static_model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "memory = ReplayMemory(400000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state, counter):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold and counter > BATCH_SIZE:\n",
    "        with torch.no_grad():\n",
    "            return model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(51)]])\n",
    "\n",
    "last_sync = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    global last_sync\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return 0.0, 0.0\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = model(state_batch.type(FloatTensor)).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE).type(Tensor)\n",
    "    next_state_values[non_final_mask] = static_model(non_final_next_states.type(FloatTensor)).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    loss = F.mse_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    return float(loss), float(torch.mean(expected_state_action_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  10\n",
      "Episode:  20\n",
      "Episode:  30\n",
      "Episode:  40\n",
      "Episode:  50\n",
      "Episode:  60\n",
      "Episode:  70\n",
      "Episode:  80\n",
      "Episode:  90\n",
      "Episode:  100\n",
      "Complete\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_episodes = 100 #how many episodes to be used for training. If # of episodes > # of sims, data will be repetitively used for training\n",
    "num_sims = 800 #how many simulations to be used for training\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "\n",
    "counter = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    if (i_episode+1)% num_sims == 0:\n",
    "        isim = num_sims\n",
    "    else:\n",
    "        isim = (i_episode+1)% num_sims\n",
    "    state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,isim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(-1,5)\n",
    "    for idyn in range(1,41):\n",
    "        counter = counter + 1\n",
    "        action = select_action(state, counter)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,isim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,isim,idyn) #+1\n",
    "            next_state = torch.from_numpy(next_state).view(-1,5)\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "\n",
    "        loss, val =optimize_model()\n",
    "    if i_episode % 10 == 9:\n",
    "        print(\"Episode: \",i_episode+1)\n",
    "    if i_episode % STATIC_UPDATE == 0:\n",
    "        static_model.load_state_dict(model.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation:  50\n",
      "Simulation:  100\n",
      "Simulation:  150\n",
      "Simulation:  200\n",
      "Simulation:  250\n",
      "Simulation:  300\n",
      "Simulation:  350\n",
      "Simulation:  400\n",
      "Simulation:  450\n",
      "Simulation:  500\n",
      "Simulation:  550\n",
      "Simulation:  600\n",
      "Simulation:  650\n",
      "Simulation:  700\n",
      "Simulation:  750\n",
      "Simulation:  800\n",
      "Simulation:  850\n",
      "Simulation:  900\n",
      "Simulation:  950\n",
      "Simulation:  1000\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "def select_best_action(state):\n",
    "    with torch.no_grad():\n",
    "        return static_model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "\n",
    "#Evaluate the model\n",
    "num_sims = 1000\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "sims = []\n",
    "sims_sim = []\n",
    "qs = []\n",
    "rwds = []\n",
    "rwds_total = []\n",
    "\n",
    "num_sims\n",
    "\n",
    "for i_sim in range(1,num_sims+1):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,i_sim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(-1,5)\n",
    "    reward_total = 0\n",
    "    for idyn in range(1,41):\n",
    "        # Select and perform an action\n",
    "        action = select_best_action(state)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,i_sim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        reward_total = reward_total + reward * GAMMA**(idyn-1)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getLSTMState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,i_sim,idyn)#+1\n",
    "            next_state = torch.from_numpy(next_state).view(-1,5)\n",
    "        state = next_state\n",
    "\n",
    "        sims.append(i_sim+1)\n",
    "        qs.append(idyn+1)\n",
    "        rwds.append(float(reward))\n",
    "    rwds_total.append(reward_total)\n",
    "    sims_sim.append(i_sim)\n",
    "    if i_sim % 50 == 49:\n",
    "        print(\"Simulation: \",i_sim+1)\n",
    "\n",
    "df = pd.DataFrame(tliabArray)\n",
    "df.to_csv('C:/dsge/py/output/lstm_wo_constraint_results_'+str(neg_multiple)+str(GAMMA)+'_'+str(BATCH_SIZE)+'_'+str(num_sims)+'.csv')\n",
    "#Output file has the following variables\n",
    "#id\n",
    "#scn\n",
    "#period\n",
    "#liability value\n",
    "#plan cost\n",
    "#accured benefit payment\n",
    "#projected benefit payment\n",
    "#AA-rated bond investment\n",
    "#public equity investment\n",
    "#total asset value\n",
    "#funding ratio\n",
    "#funding surplus\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL3: FCNN model with rebalance constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get inputs for FCNN models\n",
    "def getNewState(employees,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,sim,dyn):\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [8]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    newState = np.concatenate((thmf[dyn,:].flatten(), thmf[max(0,dyn-1),:].flatten(), thmf[max(dyn-2,0),:].flatten()))#economic environment\n",
    "    asset_alloc = liabArray[6:8]/np.sum(liabArray[6:8])\n",
    "    newState = np.append(newState,asset_alloc)\n",
    "    newState = np.append(newState,dyn)\n",
    "    newState = np.append(newState,np.sum(liabArray[6:8])/liabArray[2])\n",
    "    return newState\n",
    "\n",
    "# liabArray = np.array([1,0,planliab,0,0,0])\n",
    "# liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "# liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "# state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "#             liabArray,tmpArrays,5,5)\n",
    "# print(state.shape, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_multiple = 1.0\n",
    "#get current reward\n",
    "def getReward(employees, saa, action,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,liabAll,sim,dyn,multiple,planliab=10000000.,bs = True,\\\n",
    "            inter=\"linear\",extro=\"tar\",target=0.04):\n",
    "    \n",
    "    assetArray = liabArray[6:8]\n",
    "    if action==0: #keep current mix\n",
    "        csaa = saa\n",
    "    elif action == 1: #increase bond investment\n",
    "        csaa = np.minimum(1,np.maximum(0,saa + np.array([0.02,-0.02])))\n",
    "    else: #decrease bond investment\n",
    "        csaa = np.minimum(1,np.maximum(0,saa + np.array([-0.02,0.02])))\n",
    "\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [0,1,2,3,4,5,6,7,8,26,27,46,47]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    pboArray = liabAll[((sim-1)*ndyn+iq-1),0:4]\n",
    "    liabNCF = pboArray[1] - pboArray[2]\n",
    "    cashRtns = np.array([thmf[iq,11],thmf[iq,9]/4])\n",
    "    priceRtns = np.array([thmf[iq,12],thmf[iq,10]])\n",
    "    cashCF = np.sum(np.multiply(assetArray,cashRtns/100))\n",
    "    assetArray = assetArray+np.multiply(assetArray,priceRtns/100)\n",
    "    newAssetValue = np.sum(assetArray)\n",
    "    if bs == False and (cashCF+liabNCF) > 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    elif bs == False and (cashCF + liabNCF) <= 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    else:\n",
    "        bsArray = np.multiply((cashCF+liabNCF+newAssetValue),csaa)-assetArray\n",
    "    assetArray = assetArray + bsArray\n",
    "    pboArray = np.insert(pboArray,0,[sim,iq])\n",
    "    pboArray = np.append(pboArray,assetArray)\n",
    "    pboArray = np.append(pboArray,np.array([np.sum(assetArray),np.sum(assetArray)/pboArray[2],np.sum(assetArray)-pboArray[2]]))\n",
    "    reward = - np.sum(liabArray[6:8])/liabArray[2] + np.sum(pboArray[6:8])/pboArray[2]#reward is change in funding ratio\n",
    "    if reward < 0: reward = neg_multiple*reward    \n",
    "    return reward,pboArray,csaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define deep learning model to approximate reward function\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False #if False, CPU is used\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lin1 = nn.Linear(7, 256)\n",
    "        self.lin1c = nn.Linear(256, 128)\n",
    "        self.lin2 = nn.Linear(128, 64)\n",
    "        self.lin3 = nn.Linear(64, 32)\n",
    "        self.lin4 = nn.Linear(32, 16)\n",
    "        self.head = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        x = torch.relu(self.lin1c(x))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "        x = torch.relu(self.lin3(x))\n",
    "        x = torch.relu(self.lin4(x))\n",
    "        return self.head(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL specification\n",
    "BATCH_SIZE = 1000\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.75\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = max(1000, BATCH_SIZE)\n",
    "STATIC_UPDATE = 10 #update frequency\n",
    "\n",
    "model = DQN()\n",
    "static_model = DQN()\n",
    "static_model.load_state_dict(model.state_dict())\n",
    "static_model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "memory = ReplayMemory(400000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(3)]])\n",
    "    \n",
    "last_sync = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    global last_sync\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return 0.0, 0.0\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = model(state_batch.type(FloatTensor)).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE).type(Tensor)\n",
    "    next_state_values[non_final_mask] = static_model(non_final_next_states.type(FloatTensor)).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    loss = F.mse_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    return float(loss), float(torch.mean(expected_state_action_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  10\n",
      "Episode:  20\n",
      "Episode:  30\n",
      "Episode:  40\n",
      "Episode:  50\n",
      "Episode:  60\n",
      "Episode:  70\n",
      "Episode:  80\n",
      "Episode:  90\n",
      "Episode:  100\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_episodes = 100 #how many episodes to be used for training. If # of episodes > # of sims, data will be repetitively used for training\n",
    "num_sims = 800 #how many simulations to be used for training\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    if (i_episode+1)% num_sims == 0:\n",
    "        isim = num_sims#00\n",
    "    else:\n",
    "        isim = (i_episode+1)% num_sims\n",
    "    state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,isim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(1,7)\n",
    "    for idyn in range(1,41):\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,isim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,isim,idyn) #+1\n",
    "            next_state = torch.from_numpy(next_state).view(1,7) #208 82\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        loss, val =optimize_model()# \n",
    "    if i_episode % 10 == 9:\n",
    "        print(\"Episode: \",i_episode+1)\n",
    "    if i_episode % STATIC_UPDATE == 0:\n",
    "        static_model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation:  50\n",
      "Simulation:  100\n",
      "Simulation:  150\n",
      "Simulation:  200\n",
      "Simulation:  250\n",
      "Simulation:  300\n",
      "Simulation:  350\n",
      "Simulation:  400\n",
      "Simulation:  450\n",
      "Simulation:  500\n",
      "Simulation:  550\n",
      "Simulation:  600\n",
      "Simulation:  650\n",
      "Simulation:  700\n",
      "Simulation:  750\n",
      "Simulation:  800\n",
      "Simulation:  850\n",
      "Simulation:  900\n",
      "Simulation:  950\n",
      "Simulation:  1000\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "def select_best_action(state):\n",
    "    with torch.no_grad():\n",
    "        return static_model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "\n",
    "#Evaluate the model\n",
    "num_sims = 1000\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "sims = []\n",
    "sims_sim = []\n",
    "qs = []\n",
    "rwds = []\n",
    "rwds_total = []\n",
    "\n",
    "num_sims\n",
    "\n",
    "for i_sim in range(1,num_sims+1):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,i_sim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(1,7)\n",
    "    reward_total = 0\n",
    "    for idyn in range(1,41):\n",
    "        # Select and perform an action\n",
    "        action = select_best_action(state)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,i_sim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        reward_total = reward_total + reward * GAMMA**(idyn-1)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,i_sim,idyn)#+1\n",
    "            next_state = torch.from_numpy(next_state).view(1,7) #208 82\n",
    "        state = next_state\n",
    "\n",
    "        sims.append(i_sim+1)\n",
    "        qs.append(idyn+1)\n",
    "        rwds.append(float(reward))\n",
    "    rwds_total.append(reward_total)\n",
    "    sims_sim.append(i_sim)\n",
    "    if i_sim % 50 == 49:\n",
    "        print(\"Simulation: \",i_sim+1)\n",
    "\n",
    "df = pd.DataFrame(tliabArray)\n",
    "df.to_csv('C:/dsge/py/output/fcnn_w_constraint_results_'+str(neg_multiple)+str(GAMMA)+'_'+str(BATCH_SIZE)+'_'+str(num_sims)+'.csv')\n",
    "#Output file has the following variables\n",
    "#id\n",
    "#scn\n",
    "#period\n",
    "#liability value\n",
    "#plan cost\n",
    "#accured benefit payment\n",
    "#projected benefit payment\n",
    "#AA-rated bond investment\n",
    "#public equity investment\n",
    "#total asset value\n",
    "#funding ratio\n",
    "#funding surplus\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL4: FCNN model without rebalance constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get inputs for FCNN models\n",
    "def getNewState(employees,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,sim,dyn):\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [8]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    newState = np.concatenate((thmf[dyn,:].flatten(), thmf[max(0,dyn-1),:].flatten(), thmf[max(dyn-2,0),:].flatten()))#economic environment\n",
    "    asset_alloc = liabArray[6:8]/np.sum(liabArray[6:8])\n",
    "    newState = np.append(newState,asset_alloc)\n",
    "    newState = np.append(newState,dyn)\n",
    "    newState = np.append(newState,np.sum(liabArray[6:8])/liabArray[2])\n",
    "    return newState\n",
    "\n",
    "# liabArray = np.array([1,0,planliab,0,0,0])\n",
    "# liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "# liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "# state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "#             liabArray,tmpArrays,5,5)\n",
    "# print(state.shape, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_multiple = 1.0\n",
    "#get current reward\n",
    "def getReward(employees, saa, action,var,fundmap,histMF,histAR,cholMF,cholNormal,cholRecession,\\\n",
    "            liabArray,tmpArray,liabAll,sim,dyn,multiple,planliab=10000000.,bs = True,\\\n",
    "            inter=\"linear\",extro=\"tar\",target=0.04):\n",
    "    \n",
    "    assetArray = liabArray[6:8]\n",
    "    csaa=np.array([0.02*action.item(),1-0.02*action.item()]) #select from 51 asset allocation plans\n",
    "\n",
    "    iq = dyn\n",
    "    thmf = tmpArray[(sim*(ndyn+1)):(sim*(ndyn+1)+ndyn+1),:].copy()\n",
    "    thmf[:,47] = thmf[:,47] * 100.0\n",
    "    thmf[:,46] = thmf[:,46] * 100.0\n",
    "    keep_cols = [0,1,2,3,4,5,6,7,8,26,27,46,47]\n",
    "    thmf = thmf[:,keep_cols]\n",
    "    pboArray = liabAll[((sim-1)*ndyn+iq-1),0:4]\n",
    "    liabNCF = pboArray[1] - pboArray[2]\n",
    "    cashRtns = np.array([thmf[iq,11],thmf[iq,9]/4])\n",
    "    priceRtns = np.array([thmf[iq,12],thmf[iq,10]])\n",
    "    cashCF = np.sum(np.multiply(assetArray,cashRtns/100))\n",
    "    assetArray = assetArray+np.multiply(assetArray,priceRtns/100)\n",
    "    newAssetValue = np.sum(assetArray)\n",
    "    if bs == False and (cashCF+liabNCF) > 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    elif bs == False and (cashCF + liabNCF) <= 0:\n",
    "        bsArray = np.multiply((cashCF+liabNCF),csaa)\n",
    "    else:\n",
    "        bsArray = np.multiply((cashCF+liabNCF+newAssetValue),csaa)-assetArray\n",
    "    assetArray = assetArray + bsArray\n",
    "    pboArray = np.insert(pboArray,0,[sim,iq])\n",
    "    pboArray = np.append(pboArray,assetArray)\n",
    "    pboArray = np.append(pboArray,np.array([np.sum(assetArray),np.sum(assetArray)/pboArray[2],np.sum(assetArray)-pboArray[2]]))\n",
    "    reward = - np.sum(liabArray[6:8])/liabArray[2] + np.sum(pboArray[6:8])/pboArray[2]#reward is change in funding ratio\n",
    "    if reward < 0: reward = neg_multiple*reward    \n",
    "    return reward,pboArray,csaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define deep learning model to approximate reward function\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False #if False, CPU is used\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lin1 = nn.Linear(7, 256)\n",
    "        self.lin1c = nn.Linear(256, 128)\n",
    "        self.lin2 = nn.Linear(128, 64)\n",
    "        self.lin3 = nn.Linear(64, 32)\n",
    "        self.lin4 = nn.Linear(32, 16)\n",
    "        self.head = nn.Linear(16, 51)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        x = torch.relu(self.lin1c(x))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "        x = torch.relu(self.lin3(x))\n",
    "        x = torch.relu(self.lin4(x))\n",
    "        return self.head(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL specification\n",
    "BATCH_SIZE = 1000\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.75\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = max(1000, BATCH_SIZE)\n",
    "STATIC_UPDATE = 10 #update frequency\n",
    "\n",
    "model = DQN()\n",
    "static_model = DQN()\n",
    "static_model.load_state_dict(model.state_dict())\n",
    "static_model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "memory = ReplayMemory(400000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(51)]])\n",
    "    \n",
    "last_sync = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    global last_sync\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return 0.0, 0.0\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = model(state_batch.type(FloatTensor)).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE).type(Tensor)\n",
    "    next_state_values[non_final_mask] = static_model(non_final_next_states.type(FloatTensor)).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    loss = F.mse_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    return float(loss), float(torch.mean(expected_state_action_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  10\n",
      "Episode:  20\n",
      "Episode:  30\n",
      "Episode:  40\n",
      "Episode:  50\n",
      "Episode:  60\n",
      "Episode:  70\n",
      "Episode:  80\n",
      "Episode:  90\n",
      "Episode:  100\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_episodes = 100 #how many episodes to be used for training. If # of episodes > # of sims, data will be repetitively used for training\n",
    "num_sims = 800 #how many simulations to be used for training\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    if (i_episode+1)% num_sims == 0:\n",
    "        isim = num_sims#00\n",
    "    else:\n",
    "        isim = (i_episode+1)% num_sims\n",
    "    state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,isim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(1,7)\n",
    "    for idyn in range(1,41):\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,isim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,isim,idyn) #+1\n",
    "            next_state = torch.from_numpy(next_state).view(1,7) #208 82\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        loss, val =optimize_model()# \n",
    "    if i_episode % 10 == 9:\n",
    "        print(\"Episode: \",i_episode+1)\n",
    "    if i_episode % STATIC_UPDATE == 0:\n",
    "        static_model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation:  50\n",
      "Simulation:  100\n",
      "Simulation:  150\n",
      "Simulation:  200\n",
      "Simulation:  250\n",
      "Simulation:  300\n",
      "Simulation:  350\n",
      "Simulation:  400\n",
      "Simulation:  450\n",
      "Simulation:  500\n",
      "Simulation:  550\n",
      "Simulation:  600\n",
      "Simulation:  650\n",
      "Simulation:  700\n",
      "Simulation:  750\n",
      "Simulation:  800\n",
      "Simulation:  850\n",
      "Simulation:  900\n",
      "Simulation:  950\n",
      "Simulation:  1000\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "def select_best_action(state):\n",
    "    with torch.no_grad():\n",
    "        return static_model(state.type(FloatTensor)).max(1)[1].view(1, 1)\n",
    "\n",
    "#Evaluate the model\n",
    "num_sims = 1000\n",
    "tsaa = [0.5,0.5]\n",
    "tliabArray = np.array([1,0,planliab,0,0,0])\n",
    "tliabArray = np.append(tliabArray,np.multiply(saa,planasset))\n",
    "tliabArray = np.append(tliabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "tliabArray = np.copy(tliabArray)\n",
    "sims = []\n",
    "sims_sim = []\n",
    "qs = []\n",
    "rwds = []\n",
    "rwds_total = []\n",
    "\n",
    "num_sims\n",
    "\n",
    "for i_sim in range(1,num_sims+1):\n",
    "    # Initialize the environment and state\n",
    "    saa = [0.5,0.5]\n",
    "    liabArray = np.array([1,0,planliab,0,0,0])\n",
    "    liabArray = np.append(liabArray,np.multiply(saa,planasset))\n",
    "    liabArray = np.append(liabArray,np.array([planasset,planasset/planliab,planasset-planliab]))\n",
    "    state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                liabArray,tmpArrays,i_sim,0)\n",
    "    newInput = np.copy(liabArray)\n",
    "    state = torch.from_numpy(state).view(1,7)\n",
    "    reward_total = 0\n",
    "    for idyn in range(1,41):\n",
    "        # Select and perform an action\n",
    "        action = select_best_action(state)\n",
    "        reward,newInput,saa = getReward(employees,saa,action,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,liabAll,i_sim,idyn,multiple,planliab,bs = True,inter=\"linear\",extro=\"tar\",target=0.04)\n",
    "        reward_total = reward_total + reward * GAMMA**(idyn-1)\n",
    "        tsaa = np.vstack([tsaa,np.array(saa)])\n",
    "        tliabArray = np.vstack([tliabArray, np.array(newInput)])\n",
    "        reward = Tensor([reward])\n",
    "        if idyn == 40:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = getNewState(employees,var,fundmap,hmf,har,var1chol,normalChol,recessionChol,\\\n",
    "                newInput,tmpArrays,i_sim,idyn)#+1\n",
    "            next_state = torch.from_numpy(next_state).view(1,7) #208 82\n",
    "        state = next_state\n",
    "\n",
    "        sims.append(i_sim+1)\n",
    "        qs.append(idyn+1)\n",
    "        rwds.append(float(reward))\n",
    "    rwds_total.append(reward_total)\n",
    "    sims_sim.append(i_sim)\n",
    "    if i_sim % 50 == 49:\n",
    "        print(\"Simulation: \",i_sim+1)\n",
    "\n",
    "df = pd.DataFrame(tliabArray)\n",
    "df.to_csv('C:/dsge/py/output/fcnn_wo_constraint_results_'+str(neg_multiple)+str(GAMMA)+'_'+str(BATCH_SIZE)+'_'+str(num_sims)+'.csv')\n",
    "#Output file has the following variables\n",
    "#id\n",
    "#scn\n",
    "#period\n",
    "#liability value\n",
    "#plan cost\n",
    "#accured benefit payment\n",
    "#projected benefit payment\n",
    "#AA-rated bond investment\n",
    "#public equity investment\n",
    "#total asset value\n",
    "#funding ratio\n",
    "#funding surplus\n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
